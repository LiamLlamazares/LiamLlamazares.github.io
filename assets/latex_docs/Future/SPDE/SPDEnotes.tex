\documentclass[12pt]{article}
\special{papersize=3in,5in}
\usepackage[utf8]{inputenc}
%PACKAGES
\usepackage[colorlinks = true,
	linkcolor = blue,
	urlcolor  = black,
	citecolor = blue,
	anchorcolor = blue]{hyperref}
\usepackage[T1]{fontenc}
\makeatletter
\def\ps@pprintTitle{%
	\let\@oddhead\@empty
	\let\@evenhead\@empty
	\let\@oddfoot\@empty
	\let\@evenfoot\@oddfoot
}
\usepackage{amssymb,amsmath,physics,amsthm,xcolor,graphicx}
\usepackage[shortlabels]{enumitem}
\newtheorem{observation}{Observation}
%COMMANDS AND SYMBOLS
\newcommand{\br}[1]{\left\langle#1\right\rangle}
\newcommand\restr[2]{{\left.\kern-\nulldelimiterspace #1\vphantom{\big|} \right|_{#2}}}
\newcommand{\fall}[2]{\quad\forall\hspace{1pt} #1\in #2}
\newcommand{\A}{\mathbb{A}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\T}{{\mathbb T}}
\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Aa}{\mathcal{A}}
\newcommand{\Bb}{\mathcal{B}}
\newcommand{\Cc}{\mathcal{C}}
\newcommand{\Ee}{\mathcal{E}}
\newcommand{\Ff}{\mathcal{F}}
\newcommand{\Gg}{\mathcal{G}}
\newcommand{\Hh}{\mathcal{H}}
\newcommand{\Kk}{\mathcal{K}}
\newcommand{\Ll}{\mathcal{L}}
\newcommand{\Mm}{\mathcal{M}}
\newcommand{\Nn}{\mathcal{N}}
\newcommand{\Pp}{\mathcal{P}}
\newcommand{\Qq}{\mathcal{Q}}
\newcommand{\Rr}{{\mathcal R}}
\newcommand{\Tt}{{\mathcal T}}
\newcommand{\Zz}{{\mathcal Z}}
\newcommand{\ff}{{\mathcal F}}
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\CC}{{\mathbb C}}
\newcommand{\reals}{{\mathbb R}}
\newcommand{\PP}{{\mathbb P}}
\newcommand{\EE}{{\mathbb E}}
\newcommand{\om}{\Omega}
%ENVIRONMENTS
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newcommand{\red}[1]{{\color{red}#1}}
\usepackage[colorlinks = true,
	linkcolor = blue,
	urlcolor  = black,
	citecolor = blue,
	anchorcolor = blue]{hyperref}
\usepackage{cleveref}
\bibliographystyle{elsarticle-num}

\setlength{\parindent}{0in}

\begin{document}
\title{Stuff studied}
\author{Liam Llamazares}
\date{February 2022}
\maketitle
\section{Gaussian Random variables}
\subsection{To Banach spaces}
Let $E$ be a Banach space and $(\Omega,\mathcal{F},\mathbb{P})$ a probability space
\begin{definition}
	A \emph{Gaussian probability measure on $E$} is a Borel measure $\mu$ such that  for all \(\ell\in E^*\) it holds that \(\ell^*\mu\)  is a Gaussian measure on $\R$.
\end{definition}
\begin{definition}
	A Gaussian random variable to $E$ is a measurable function \(W:(\Omega,\mathcal{F})\to (E,\mathcal{B}(E)\) such that for all \(\ell\in E^*\) we have that \(\ell(W)\) is a Gaussian random variable.
\end{definition}
\begin{proposition}
	Let $\mu,\nu$ be two finite measures on a separable Banach space $E$, then
	\begin{equation*}
		\mu=\nu\iff \ell^*\mu=\ell^*\nu\quad\forall \ell\in E^*
	\end{equation*}
\end{proposition}
\begin{proof}
	See Hairer, use separability to show that the $\sigma-$algebra generated by cylinders is the same as the Borel $\sigma-$algebra. Since the two measure coincide on cylinders $T^{-1}(\R^d)$ for $T$ continuous (by knowledge that measures on $\R^d$ are determined by their projections) also on the generated $\sigma-$algebra (by finiteness of measure).
\end{proof}
\begin{proposition}
	Let $\mu$ be a measure on a separable Banach space, then $\mu$ is determined by it's Fourier transform
\end{proposition}
\begin{proof}
	In the particular case $\mathcal{B}=\mathbb{R}^{n}$, if $\varphi$ is a smooth function with compact support, it follows from Fubini's theorem and the invertibility of the Fourier transform that one has the identity
	$$
		\int_{\mathbb{R}^{n}} \varphi(x) \mu(d x)=\frac{1}{(2 \pi)^{n}} \int_{\mathbb{R}^{n}} \int_{\mathbb{R}^{n}} \hat{\varphi}(\xi) e^{-i \xi\cdot x} d \xi \mu(d x)=\frac{1}{(2 \pi)^{n}} \int_{\mathbb{R}^{n}} \hat{\varphi}(\xi) \hat{\mu}(-\xi\cdot) d \xi,
	$$
	so that, since bounded continuous functions can be approximated by smooth functions, $\mu$ is indeed determined by $\hat{\mu}$. The general case then follows immediately from the previous proposition.
\end{proof}
\begin{definition}
	Given a Gaussian random measure $\mu$ and a Gaussian random variable $W$ we define the covariance of $W$ to be $C_\mu,C_W:E^*\times E^*\to \R$
	\begin{equation*}
		C_\mu(\ell_1,\ell_2):=\mathrm{Cov}_\mu[\ell_1,\ell_2];\quad C_W(\ell_1,\ell_2):=C_{\mathbb{P}_W}(\ell_1,\ell_2)=\mathrm{Cov}[\ell_1(W),\ell_2(W)]
	\end{equation*}
\end{definition}
Note that $C_W$ is symmetric, positive definite and bi-linear. Furthermore we can define $\tilde{C}_W:E^*\to E^{**}$ as $\tilde{C}_W(\ell_1)(\ell_2)L={C}_W(\ell_1,\ell_2)$.
\begin{proposition}
	Let $\mu$ be a Gaussian measure a separable Banach space $E$, then $C_\mu$ is continuous and $\tilde{C}_\mu$ has image in $E$
\end{proposition}
\begin{proof}
	This follow's from Fernique's theorem, see Hairer.
\end{proof}
\begin{definition}
	The \emph{reproducing kernel Hilbert space associated with $W$} is the completion of $E^*$ with the norm
	\begin{equation*}
		\norm{\ell}_{R_W}:=\sqrt{ C_W(\ell,\ell)}
	\end{equation*}
	and is written $R_W$
\end{definition}
\subsection{To Hilbert spaces}
Let $U$ be a separable Hilbert space, then we make the following definitions.
\begin{definition}\label{Gaussian measure}
	A measure $\mu$ on  \((U,\mathcal{B}(U))\) is said to be Gaussian if
	for all \(u\in U\) there exist \(m(u),\sigma(u)\) such that, for \(\sigma(u)\neq 0\)
	\[\mu_{\langle\cdot,u\rangle}(A)=\int_A f(m(u),\sigma^2(u),s)ds\quad\forall A\in\mathcal{B}(\mathbb{R}).\]
	Where $f(m,\sigma^2,\cdot)$ is the density of a normal random variable with mean $m$ and variance $\sigma^2$.
	And otherwise
	\[\mu_{\langle\cdot,u\rangle}=\delta_{m(u)}.\]
\end{definition}
\begin{definition}
	The Fourier transform of $\mu$ is the function $\hat{\mu}:U\to\R$ defined by
	\[\hat{\mu}(v):=\int_U e^{i\langle u,v\rangle}d\mu(v).\]
\end{definition}

\begin{proposition}\label{exp}
	A measure $\mu$ on $(U, \mathcal{B}(U))$ is Gaussian if and only if
	$$
		\hat{\mu}(u):=\int_{U} e^{i\langle u, v\rangle_{U}} \mu(d v)=e^{i\langle m, u\rangle_{U}-\frac{1}{2}\langle Q u, u\rangle_{U}}, \quad u \in U,
	$$
	where $m \in U$ and $Q \in L(U)$ is non-negative, symmetric, with finite trace. In this case $\mu$ will be denoted by $N(m, Q)$ where $m$ is called the mean and $Q$ is called the covariance (operator). The measure $\mu$ is uniquely determined by $m$ and $Q$.
	Furthermore, for all $h, g \in U$
	\begin{align*}
		\int_U\langle x, h\rangle_{U} \mu(d x)                                                                                                  & =\langle m, h\rangle_{U},   \\
		\int_U\left(\langle x, h\rangle_{U}-\langle m, h\rangle_{U}\right)\left(\langle x, g\rangle_{U}-\langle m, g\rangle_{U}\right) \mu(d x) & =\langle Q h, g\rangle_{U}, \\
		\int_U\|x-m\|_{U}^2 \mu(d x)                                                                                                            & =\operatorname{tr} Q .
	\end{align*}
\end{proposition}
It follows from the above proposition that, the values of $m(u),\sigma(u)$ in Definition \ref{Gaussian measure} are
\begin{equation*}
	m(u)=\br{m,u};\quad \sigma^2(u)=\br{Qu,u}.
\end{equation*}
Using this we can get the following representation theorem
\begin{proposition}(Representation of a Gaussian Random Variable) Let $m \in U$ and $Q \in L(U)$ be non-negative, symmetric, with $\operatorname{tr} Q<\infty$. Let $e_{k}$ be an orthonormal basis of $U$ consisting of eigenvectors of $Q$ with eigenvalues $\lambda_{k}.$
	Then a $U$-valued random variable $X$ on a probability space $(\Omega, \mathcal{F}, P)$ is Gaussian with $P \circ X^{-1}=N(m, Q)$ if and only if
	$$
		X=\sum_{k \in \mathbb{N}} \sqrt{\lambda_{k}} \beta_{k} e_{k}+m \quad\left(\text { as objects in } L^2(\Omega, \mathcal{F}, P ; U)\right)
	$$
	where $\beta_{k}, k \in \mathbb{N}$, are independent real-valued random variables with $P \circ \beta_{k}^{-1}=$ $N(0,1)$ for all $k \in \mathbb{N}$ with $\lambda_{k}>0$. The series converges in $L^2(\Omega, \mathcal{F}, P ; U)$.
\end{proposition}
The idea of the implication is to take $\beta_k$ to be
\begin{equation*}
	\beta_{k}:=\left\{\begin{array}{ll}
		=\frac{\left\langle X, e_{k}\right\rangle-\left\langle m, e_{k}\right\rangle}{\sqrt{\lambda_{k}}} & \text { if } \lambda_{k}>0 \\
		\equiv 0 \in \mathbb{R}                                                                           & \text { else.}
	\end{array}\right.
\end{equation*}
Then we get that $\beta_k\sim\mathcal{N}(0,1)$ by the previous. It remains to show that they are independent.\\
\\
The idea of the reciprocal is as follows. By construction we have that the finite sums are Gaussian. Furthermore, the infinite sum converges in $L^2(\Omega, \mathcal{F}, P ; U)$ so it is also Gaussian (use the characteristic function and dominated convergence theorem and independence and the below lemma). The calculation of the mean and the covariance is a calculation using \eqref{exp}.
\begin{lemma}
	Let $Q$ be non-negative, symmetric and with finite trace and consider an orthonormal family $\{e_k,\lambda_k\}$. Then if $\beta_k\sim\mathcal{N}(0,1)$ we have
	\begin{equation*}
		X_k:=\sqrt{\lambda_k}\beta_k e_k+m_k\sim\mathcal{N}(m_k,P_kQ)
	\end{equation*}
	Where $P_k$ is the projection onto $e_k$.
\end{lemma}
\begin{proof}
	By considering the definition of Gaussian random variable we obtain that is is Gaussian
	with $m(u)=\br{m_k,u}$ and
	\begin{equation*}
		\sigma^2(u)=\lambda_k\br{e_k,u}^2=\br{Qe_k,u}\br{e_k,u}=\br{P_kQu,u}.
	\end{equation*}
	Since we have seen that
	\begin{equation*}
		m(u)=\br{m,u};\quad \sigma^2(u)=\br{Qu,u}.
	\end{equation*}
	This concludes the proof.
\end{proof}
As a corollary of the representation theorem we get the following.
\begin{corollary} Given $m,Q$ there exists a Gaussian random variable $X\sim\mathcal{N}(m,Q)$ and a Gaussian random measure $\mu=\mathcal{N}(m,Q)$.
\end{corollary}
By using the definition  of Gaussian measure it is possible to define the meaning of a Wiener process taking values in $U$.
\begin{definition}
	A $U$ valued standard $Q$-Wiener process is a stochastic process
	\begin{equation*}
		W:(\Omega,\mathcal{F},\mathbb{P})\to U
	\end{equation*}
	such that
	\begin{enumerate}
		\item $W(0)=0$.
		\item $W$ has $\PP$ almost everywhere continuous trajectories.
		\item The increments $W(t_1),W(t_2)-W(t_1),W(t_3)-W(t_2)....$ are independent random variables
		\item $W(t)-W(s)\sim \mathcal{N}(0,(t-s)Q)$ for all $t\geq s$. That is, for all $A\in\mathcal{B}(\R))$ and all $u\in U$
		      \begin{equation*}
			      \mathbb{P}(\br{W(t)-W(s),u}\in A)=\frac{1}{\sqrt{2\pi\br{Qu,u}}}\int_A\exp(-\frac{x^2}{2\br{Qu,u}})dx.
		      \end{equation*}
	\end{enumerate}
\end{definition}
\begin{lemma}[Doob's maximal Martingale inequality]
	Let $\{X_k\}_{k=1}^\infty$ be a sub-martingale. Then it holds that
	\begin{equation*}
		\norm{\max_{k\in\{1,...,n\}}X_k}_{L^p(\Omega)}\leq \frac{p}{p-1}\norm{X_n}_{L^p(\Omega)}
	\end{equation*}
	As a consequence, if $X_t,t\in[0,T]$ is a left (or right) continuous semi-martingale then
	\begin{equation*}
		\norm{\max_{t\in[0,T]}X_k}_{L^p(\Omega)}\leq \frac{p}{p-1}\norm{X_T}_{L^p(\Omega)}.
	\end{equation*}
\end{lemma}
\begin{proof}
	We only show how to get from the discrete to the continuous case. Take
	\begin{equation*}
		F_j:= \{0,t_0,...,t_j,T\}; \quad \{t_j\}_{j=1}^\infty =\mathbb{Q}\cap [0,T]
	\end{equation*}
	Then $F_j\subset F_{j+1}$ so $\max_{t\in F_j}X_t$ is an increasing sequence. And by continuity it converges to $\max_{t\in[0,T]}X_t$. So by the discrete case.
	\begin{equation*}
		\norm{\max_{t\in[0,T]}X_t}_{L^p(\Omega)}=\lim_{j\to\infty}\norm{\max_{t\in F_j}X_t}_{L^p(\Omega)}\leq \lim_{j\to\infty}\frac{p}{p-1}\norm{X_T}_{L^p(\Omega)}=\frac{p}{p-1}\norm{X_T}_{L^p(\Omega)}
	\end{equation*}
\end{proof}
As a result of this and the previous proposition we get the following representation theorem
\begin{proposition}(Representation of a $Q$-Wiener Process) Let $Q \in L(U)$ be non-negative, symmetric, with $\operatorname{tr} Q<\infty$. Let $e_{k}$ be an orthonormal basis of $U$ consisting of eigenvectors of $Q$ with eigenvalues $\lambda_{k}.$
	Then a $U$-valued process $W$ on a probability space $(\Omega, \mathcal{F}, P)$ is a $Q$-Wiener Process if and only if
	$$
		X(t)=\sum_{k \in \mathbb{N}} \sqrt{\lambda_{k}} \beta_{k}(t) e_{k} \quad\left(\text { as objects in } L^2(\Omega, \mathcal{F}, P ; U)\right)
	$$
	where $\beta_{k}, k \in \mathbb{N}$, are independent real-valued Wiener processes on $(\Omega, \mathcal{F}, P)$ for all $k \in \mathbb{N}$ with $\lambda_{k}>0$. Furthermore, the series converges in $L^2(\Omega\to C([0,T]\to U))$.
\end{proposition}
\begin{proof}
	To prove the implication we note that, by previous results, it holds that for
	\begin{equation*}
		\beta_{k}:=\left\{\begin{array}{ll}
			=\frac{\left\langle W, e_{k}\right\rangle}{\sqrt{\lambda_{k}}} & \text { if } \lambda_{k}>0 \\
			\equiv 0 \in \mathbb{R}                                        & \text { else.}
		\end{array}\right.
	\end{equation*}
	we have $\beta_k(t)\sim\mathcal{N}(0,t)$. For the same reason
	\begin{equation*}
		\beta_{k}(t)-\beta_{k}(s)=\frac{\left\langle W(t)-W(s), e_{k}\right\rangle}{\sqrt{\lambda_{k}}}
	\end{equation*}
	follows a $\mathcal{N}(0,t-s)$. The continuity of $\beta_k$ is also clear by the continuity of $W_k$ and they start at $0$. It remains to check independence this is technical.\\
	\\
	To prove the reverse implication we note that convergence holds in the above space by Doob's maximal Martingale inequality
	\begin{multline*}
		E\left(\sup _{t \in[0, T]}\left\|W^{N}(t)-W^{M}(t)\right\|_{U}^2\right)=E\left(\sup _{t \in[0, T]} \sum_{k=M+1}^{N} \lambda_{k} \beta_{k}^2(t)\right) \\
		\quad \leq \sum_{k=M+1}^{N} \lambda_{k} E\left(\sup _{t \in[0, T]} \beta_{k}^2(t)\right) \leq 4 \sum_{k=M+1}^{N} \lambda_{k} \sup _{t \in[0, T]} E\left(\beta_{k}(t)^2\right) \leq 4 T \sum_{k=M+1}^{N} \lambda_{k}.
	\end{multline*}
	The independence of the increments and that $W(t)-W(s)\sim \mathcal{N}(0,Q(t-s))$ is a calculation. The fact that the process starts at $0$ is also clear as $\beta_k(0)=0$.
\end{proof}

We now define the filtrations with respect to which we will consider adapted Wiener processes. These verify two properties, completeness and continuity.
\begin{definition}
	A \emph{normal filtration} $\mathcal{F}_t$ is a filtration such that
	\begin{enumerate}
		\item All sets with measure $0$ are in $\mathcal{F}_0$.
		\item $\ff_s=\ff_{s_+}=\bigcap_{s<t}\ff_t$ for all $s\in [0,T)$.
	\end{enumerate}
\end{definition}
The purpose of the first requirement is so that adaptations of adapted processes are also adapted. Though it is not necessary to construct the stochastic integral.
\begin{definition}
	A $Q-$WIener process $W(t)$ is called a $Q$-Wiener process with respect to a normal filtration $\mathcal{F}_t$ if
	\begin{enumerate}
		\item $W(t)$ is adapted to $\mathcal{F}_t$.
		\item $W(t)-W(s)$ is independent of $\ff_S$ for all $0\leq s\leq t\leq T$.
	\end{enumerate}
\end{definition}
Given any $Q$-Wiener process $W$ it can be shown that it is a WIener process wrt the filtration
\begin{equation*}
	\mathcal{F}_s:=\bigcap_{s<t}\sigma\qty(\tilde{\ff}_t\cup\mathcal{N}_0);\quad \tilde{\ff}_t=\sigma(\{W_r:r\leq t\});\quad \mathcal{N}_0=\{ A\in\ff:\PP(A)=0\}
\end{equation*}
\newpage
\section{The Bochner integral}
We now define integration for functions valued in a Banach space \begin{equation*}
	f:(\Omega,\mathcal{F},\mu)\to ((X,\norm{\cdot}),\mathcal{B}(X))
\end{equation*}
If we denote the class of simple functions by $\mathcal{A}$ we can define their integral as
\begin{equation*}
	\int f d\mu=\int \sum_{k=1}^n x_k 1_{A_k} d\mu=\sum_{k=1}^n x_k\mu({A_k})
\end{equation*}
If we take equivalence class and define the norm
\begin{equation*}
	\norm{f}_\mathcal{A}:=\int_\Omega \norm{f} d\mu.
\end{equation*}
Then we get that integration is a linear and absolutely continuous function
\begin{equation*}
	int: \qty(\mathcal{A},\norm{\cdot}_A)\to (X,\norm{\cdot}).
\end{equation*}
as for all $f\in\mathcal{A}$
\begin{equation*}
	\norm{\int_\Omega f}\leq\int_\Omega \norm{f} d\mu=\norm{f}_\mathcal{A}
\end{equation*}
This shows that we can extend integration in a unique way to the completion $\Bar{\mathcal{A}}$ of $\qty(\mathcal{A},\norm{\cdot}_A)$.
\begin{definition}
	We say a function $f:(\Omega,\mathcal{F})\to (X,\mathcal{B}(X))$ is strongly measurable if $f$ is measurable $f(\Omega)$ is separable.
\end{definition}
\begin{definition}
	For $1\leq p<\infty$ we define
	\begin{align*}
		\mathcal{L}^p(\Omega,\mathcal{F},\mu,X)       & =\left\{f:\Omega\to X: f \text{ is strongly measurable and } \int \norm{f}^p d\mu<\infty\right\}. \\
		\hat{\mathcal{L}}^p(\Omega,\mathcal{F},\mu,X) & =\left\{f:\Omega\to X: \int \norm{f}^p d\mu<\infty\right\}.
	\end{align*}
	We also define the semi-norms
	\begin{align*}
		\norm{f}_{L^p(\Omega\to X)}       & :=\qty(\int \norm{f}^p d\mu)^{1/p},\quad f\in\mathcal{L}^p(\Omega,\mathcal{F},\mu,X).       \\
		\norm{f}_{\hat{L}^p(\Omega\to X)} & :=\qty(\int \norm{f}^p d\mu)^{1/p},\quad f\in\hat{\mathcal{L}}^p(\Omega,\mathcal{F},\mu,X).
	\end{align*}
	Finally we take equivalence classes by the above semi-norms to obtain the metric spaces $L^p(\Omega\to X)$ and $\hat{L}^p(\Omega\to X).$
\end{definition}
A straightforward adaptation of the proof of the completion of $L^p$ spaces proves that $L^p(\Omega\to X)$ and $\hat{L}^p(\Omega\to X)$ are also complete.
\begin{proposition}
	Given a Banach space $X$, the space of $p$ integrable strongly measurable and measurable functions $L^p(\Omega\to X),\hat{L}^p(\Omega\to X)$ are Banach spaces.
\end{proposition}
\begin{proof}
	The proof is identical in both cases so we prove it only for $f\in L^p(\Omega\to X)$
	It suffices to show that if $f_n$ is such that
	\begin{equation*}
		\sum_{n=1}^\infty \norm{f_n}_{L^p(\Omega\to X)}<\infty.
	\end{equation*}
	Then there exists $f\in L^p(\Omega\to X)$ such that
	\begin{equation*}
		f=\sum_{n=1}^\infty f_n\in L^p(\Omega\to X).
	\end{equation*}
	To do so we apply Minkowski's inequality for real valued functions to show that
	\begin{equation*}
		\sum_{n=1}^\infty \norm{f_n}_X\in L^p(\Omega\to\R).
	\end{equation*}
	and is thus finite almost everywhere. Since $X$ is complete we have that the below sum converges pointwise almost everywhere to some function
	\begin{equation*}
		f(\omega):=\sum_{n=1}^\infty f_n(\omega)\in X.
	\end{equation*}
	Furthermore we have that $f$ is strongly measurable as it is the limit of strongly measurable functions and, by Fatou's lemma for real valued functions and the triangle inequality for norms
	\begin{multline*}
		\norm{f-\sum_{n=1}^N f_n}_{L^p(\Omega\to X)}=\norm{\sum_{n=N}^\infty f_n}_{L^p(\Omega\to X)}\leq \liminf_{M\to \infty}\norm{\sum_{n=N}^M f_n}_{L^p(\Omega\to X)}\\\leq \liminf_{M\to \infty}\sum_{n=N}^M \norm{f_n}_{L^p(\Omega\to X)}=\sum_{n=N}^\infty \norm{f_n}_{L^p(\Omega\to X)}\xrightarrow{N\to\infty} 0.
	\end{multline*}
	Which shows convergence in $L^p(\Omega\to X)$.
\end{proof}
In the standard construction of the Lebesgue integral it is used that every measurable function to $\mathbb{R}$ can be pointwise approximated by simple functions. One can achieve the same result for arbitrary metric spaces if the image of $f$ is separable.
\begin{lemma}
	Let $(E,d)$ be a metric space and let $f$ be strongly measurable. Then $f$ is the pointwise limit of simple functions $f_n$. Furthermore, \\$d_n(\omega):=d(f_n(\omega),f(\omega))$ is a non-increasing sequence for each $\omega\in\Omega$
\end{lemma}
\begin{proof}
	Consider $\{e_k\}_{k=1}^\infty$ to be dense in $f(\Omega)$. Now set
	\begin{equation*}
		f_n(\omega):= \argmin_{i\in\{1,...,n\}} \{d(f(\omega),e_i)\}
	\end{equation*}
	Since for each fixed $\omega$ the above distance goes to $0$ we have that
	\begin{equation*}
		\lim_{n\to\infty} f_n(\omega)=f(\omega),\quad \forall \omega\in\Omega.
	\end{equation*}
	Furthermore, $f_n$ is simple as $f_n(\Omega)\in \{e_1,...,e_n\}$ and the non-increasing property of $d_n(\omega)$ is clear by construction.
\end{proof}
In the above proof we see that the reason for requiring that the image of our class of integrable functions be separable is so that we can approximate them by simple functions.
\begin{proposition}
	Every function $f\in L^1(\Omega\to X)$ is the limit of simple functions.
\end{proposition}
\begin{proof}
	Since $f(\Omega)$ is dense we can apply the above lemma to obtain a sequence of simple functions $f_n$ converging point-wise to $f$. Furthermore we have that, by the monotone convergence theorem for integrals in $\mathbb{R}$
	\begin{equation*}
		\lim_{n\to\infty}\norm{f_n-f}_{L^1(\Omega\to X)}=\lim_{n\to\infty}\int_\Omega\norm{f_n-f}d\mu=0.
	\end{equation*}
\end{proof}
As a corollary we obtain the following
\begin{corollary}
	$\mathcal{A}$ is a dense subset of $\qty(L^1(\Omega\to X),\norm{\cdot}_{L^1(\Omega\to X)})$.
\end{corollary}
In consequence, by the linearity and continuity of the integral and the above density, we have a unique continuous extension of the integral to $L^1(\Omega\to X)$.
\begin{definition}
	We define the integral on $L^1(\Omega\to X)$ as the unique continuous extension with the norm $\norm{\cdot}_{L^1(\Omega\to X)}$ of the integral on $\mathcal{A}$. That is, given $f\in L^1(\Omega\to X)$ we define
	\begin{equation*}
		\int_\Omega f d\mu:=\lim_{n\to\infty} \int_\Omega f_n d\mu.
	\end{equation*}
	Where $f_n\in \mathcal{A}$ is any sequence such that $\norm{f-f_n}_{L^1(\Omega\to X)}\to 0$.
\end{definition}
As a result of the definition the following is immediate.
\begin{corollary}
	Let $f\in L^1(\Omega,X)$ with $X$ a Banach space, then
	\begin{enumerate}
		\item $\norm{\int_\Omega f d\mu}\leq\int_\Omega{\norm{f}d\mu} $
		\item Let $Y$ be another Banach space and $L\in L(X,Y)$. Then
		      \begin{equation*}
			      \int_\Omega L\circ f d\mu=L\qty(\int_\Omega f d\mu).
		      \end{equation*}
	\end{enumerate}
\end{corollary}


\section{Martingales}
One can use the Bochner integral to extend the existence of conditional probabilities to random variables in $L^1(\Omega\to X)$. This is done by proving existence for simple functions and then taking limits as every Bochner integrable function is limit of simple functions. This allows us to define the concept of Martingale.
\begin{definition}
	Let $M(t), t \geq 0$, be a stochastic process on $(\Omega, \mathcal{F}, \mathbb{P})$ with values in a separable Banach space $E$, and let $\mathcal{F}_{t}, t \geq 0$, be a filtration on $(\Omega, \mathcal{F}, P)$.
	The process $M$ is called an $\mathcal{F}_{t}$-martingale, if:
	\begin{enumerate}
		\item $E(\|M(t)\|)<\infty$ for all $t \geq 0$,
		\item $M(t)$ is $\mathcal{F}_{t}$-measurable for all $t \geq 0$,
		\item $E\left(M(t) |\mathcal{F}_{s}\right)=M(s), \mathbb{P}$-a.s. for all $0 \leq s \leq t<\infty$.
	\end{enumerate}
\end{definition}
Using that given a separable Hilbert space $E$ there exists a sequence of linear operators $l_n$ such that
\begin{equation*}
	\norm{z}=\sup_n l_n(z)\quad\forall z\in E.
\end{equation*}
We can deduce using the linearity of the Bochner integral that, if $M$ is a martingale then $\norm{M}$ is a submartingale. Furthermore, by the conditional version of Jensen's inequality it holds that if $\varphi$ is a convex lower semi continuous function or convex and increasing and such that $\varphi(M(t))\in L^1(\Omega\to E)$ for all $t$ then $\varphi(M(t)$ is a sub-martingale. Now applying Doob's maximal inequality gives that
\begin{theorem}[Maximal Inequality]\label{doobs Hilbert} Let $p>1$ and let $E$ be a separable Banach space.
	If $M(t), t \in[0, T]$, is a right-continuous $E$-valued $\mathcal{F}_{t}$-martingale, then
	\begin{multline*}
		\left(E\left(\sup _{t \in[0, T]}\|M(t)\|^{p}\right)\right)^{\frac{1}{p}} \leq \frac{p}{p-1} \sup _{t \in[0, T]}\left(E\left(\|M(t)\|^{p}\right)\right)^{\frac{1}{p}} \\
		=\frac{p}{p-1}\left(E\left(\|M(T)\|^{p}\right)\right)^{\frac{1}{p}}
	\end{multline*}
\end{theorem}
\begin{proof}
	This follows by using that $\norm{M(t)}$ is a sub-martingale and Doob's maximal inequality.
\end{proof}
\begin{corollary}
	Let $M$ be a continuous martingale to a separable Banach space $E$. Then the following are equivalent
	\begin{itemize}
		\item $M\in \hat{L}^\infty([0,T]\to \hat{L}^2(\Omega\to E))$
		\item  $M\in \hat{L}^2(\Omega\to \hat{L}^\infty([0,T]\to E))$
		\item $\mathbb{E}[\norm{M(T)}^2]<\infty$
	\end{itemize}
\end{corollary}
A useful space of Martingales is as follows
\begin{definition}
	Let $E$ be a separable Banach space, then we define
	\begin{equation*}
		\mathcal{M}_T^2(E):=\left\{\text{continuous martingales } M:\mathbb{E}[\norm{M(T)}^2]<\infty\right\}
	\end{equation*}
	and give it the norm
	\begin{equation*}
		\norm{M}_{\mathcal{M}_T^2(E)}:=\mathbb{E}[\norm{M(T)}^2].
	\end{equation*}
\end{definition}
By Theorem \eqref{doobs Hilbert} we have that
\begin{equation*}
	\mathcal{M}_T^2(E)\subset \hat{L}^\infty([0,T]\to \hat{L}^2(\Omega\to E))\cap \hat{L}^2(\Omega\to \hat{L}^\infty([0,T]\to E)).
\end{equation*}
and that any of the norms of these spaces is equivalent to the one set on $\mathcal{M}_T^2(E)$. This is useful in the following result
\begin{proposition}
	Let $E$ be a separable Banach space, then $\mathcal{M}_T^2(E)$ is a Banach space.
\end{proposition}
\begin{proof}
	By the previous observation  and the Fischer-Riesz theorem, $\mathcal{M}_T^2(E)$ is a subspace of a Hilbert space. As a result it is sufficient to show that it is closed. Let $M_n$ converge to $M$. Then, by the equivalence of the norms we have that $M_n(t)\to M(t)\in \hat{L}^1(\Omega\to E)\subset \hat{L}^2(\Omega\to E)$ so that for all $A\in\mathcal{F}_s$
	\begin{equation*}
		\int_A M(s)d\mathbb{P}=\lim_{n\to\infty}\int_A M_n(s)d\mathbb{P}=\lim_{n\to\infty}\int_A M_n(t)d\mathbb{P}=\int_A M(t)d\mathbb{P}.
	\end{equation*}
	This shows that $M$ is a martingale. Furthermoe, as was seen in the proof of the Fischer Riesz theorem, there exists a subsequence $M_{n_k}$ such that
	\begin{equation*}
		\lim_{n\to\infty}{M_{n_k}}(\omega)=M(\omega)\in \hat{L}^\infty([0,T]\to E)\quad a.e.\quad \omega\in\Omega
	\end{equation*}
	Since $M_{n_k}(\omega)$ are continuous and continuity is preserved by uniform limits this proves that $M$ is continuous almost everywhere. This concludes the proof.
\end{proof}
\begin{proposition}
	Let $W(t)$ be a $E$ valued $\Sigma$-Wiener process with respect to a filtration $\mathcal{F}_t$. Then $W(t)\in \mathcal{M}_T^2(E)$.
\end{proposition}
\begin{proof}
	It is a martingale as it is adapted and, given $A\in\ff_S$ and $u\in E$, by linearity of the integral and Independence of $W(t)-W(s)$ with $\ff_s$
	\begin{multline*}
		\br{\int_A W(t)-W(s)d\PP,u}=\int_A \br{W(t)-W(s),u}d\PP\\=
		\PP(A)\EE[\br{W(t)-W(s),u}]=0
	\end{multline*}
	As a result
	\begin{equation*}
		\int_A W(t)d\PP=\int_A W(s)d\PP=0\quad \forall A\in\ff_s\implies \EE_s[W(t)]=W(s).
	\end{equation*}
	Finally, we have that $\EE[W(t)^2]=t<\infty$ for all $t$ and $W$ is continuous by construction. This concludes the proof.
\end{proof}
\section{Operators}
\begin{proposition}
	Let $X$ be a normed space, then the only open subspace of $X$ is itself.
\end{proposition}
\begin{proof}
	Let $U\subset X$ be an open subspace and choose $y\notin U$, then, by linearity, $\lambda_n y\notin U$ for all $\lambda_n\in\mathbb{K}$. Choose $\lambda_n\to 0$, then $\lambda_n x\to 0 \in U$. As a result $U^c$ is not closed which is a contradiction.
\end{proof}
\begin{proposition}
	Let $X, Y$ be normed spaces, then if $T\in\mathcal{L}(X,Y)$ is open it is also surjective
\end{proposition}
\begin{proof}
	$T(X)$ is open and a linear subspace.
\end{proof}
\begin{proposition}[Linear mapping theorem]
	Let $E_1,E_2$ be Banach spaces, then any surjective mapping $T\in\mathcal{L}(E_1,E_2)$ is open.
\end{proposition}
\begin{proposition}[Homeomorphism theorem]
	Let $E_1,E_2$ be Banach spaces, then $T\in\mathcal{L}(E_1,E_2)$ is a homeomorphism iff it is bijective.
\end{proposition}
\begin{proof}
	By the open mapping theorem a linear (continuous) operator is open iff it is surjective. Since $T$ is surjective it is open so $T^{-1}$ is continuous.
\end{proof}
\subsection{Compact operators}
Let $X,Y$ be normed spaces.
\begin{definition}
	We say that an operator $T$ is compact if it transforms bounded sets into relatively compact sets.
\end{definition}
Note that by definition any compact operator must be continuous as relatively compact sets must be bounded. However the reverse is not true, for example $T=Id$ on $l^2$. The reason for this is because $l^2$ does not have finite dimension however, since every bounded set in $\R^n$ is relatively compact we obtain the following.
\begin{proposition}
	Le $T:X\to Y$ have finite range, then $T$ is compact $\iff$ it is continuous.
\end{proposition}
\begin{proposition}
	The identity is relatively compact $\iff$ $X$ has finite dimension
\end{proposition}
\begin{proof}
	$\bar{B}(0,1)$ is compact $\iff$ the dimension of $X$ is finite.
\end{proof}
\begin{proposition}
	$T$ is compact $\iff T(B(0,r))$ is relatively compact for some $r\in\R\iff T(B(0,r))$
\end{proposition}
\begin{proof}
	The implication is clear, let $A\subset X$ be bounded. Then for some $r\in\R$
	\begin{equation*}
		T(A)\subset T(B(0,R))=\frac{R}{r} T(B(0,r))
	\end{equation*}
	Since any closed set within a compact set is compact and this concludes the proof.
\end{proof}
Let us write $\mathcal{K}(X,Y)$ for the space of relatively compact linear operators, then
\begin{proposition}
	Let $T:X\to Y$ be a linear operator, then
	\begin{itemize}
		\item $\mathcal{K}(X,Y)$ is a vector space.
		\item The composition of a continuous and compact operator is compact.
		\item An isomorphism is compact $\iff dim(X)<\infty$
	\end{itemize}
\end{proposition}
\begin{proof}
	The first two items can be proven using convergent sub-sequences. The second follows from considering $Id=T\circ T^{-1}$ together with the second item.
\end{proof}

\begin{proposition}
	Let $T:X\to Y$ with $Y$ complete. Then if $T_n$ are compact operators converging in $\mathcal{L}(X\to Y)$ to $T$ we have that $T$ is relatively compact.
\end{proposition}
\begin{proof}
	This follows from the fact that in complete normed spaces compactness is equivalent to total boundedness. So if we cover $T_N(A)$ by $B(y_n,\epsilon/2)$ then for large $N$ and $x\in A$
	\begin{equation*}
		\norm{T(x)-y_n}\leq \norm{T-T_N}\norm{x}-\norm{T_N(x)-y_n}<\epsilon
	\end{equation*}
\end{proof}
\begin{proposition}
	Let $T$ be a compact operator between normed spaces, then $T(X)$ is separable
\end{proposition}
\begin{proof}
	We have that $T(X)$ is the union of $T(B_n(0))$ which are separable as ther are relatively compact and thus totally bounded.
\end{proof}
\subsection{Fredholm alternative}
\begin{proposition}
	Let $T\in\mathcal{K}(E)$ with $E$ a Banach space, then $\ker(T-\lambda I)$ isa finite dimensional vector space for all $\lambda\in\mathbb{K}$.
\end{proposition}
\begin{proof}
	Since $T$ is compact so is $\frac{T}{\lambda}$, also when restricted to $\ker(T/\lambda-I)=\ker(T-\lambda I)$. But is is the identity here so this space must have finite. dimension
\end{proof}
\subsection{Invertible operators}
Let $E$ be a Banach space we recall that $\mathcal{L}(E)$ is a ring and that we say that $T\in\mathcal{L}(E)$ is invertible if $T^{-1}\in\mathcal{L}(E)$. Our next proposition states that, if an operator is not too far from the identity, then it is invertible.
\begin{proposition}
	If $T\in\mathcal{L}(E)$ is such that $\norm{T}<1$ then $I-T$ is invertible with inverse
	\begin{equation*}
		(I-T)^{-1}=\sum_{n=1}^\infty T^n
	\end{equation*}
	\begin{proof}
		This follows from the completeness of $\mathcal{L}(E)$ and the fact that the above series is normally convergent.
	\end{proof}
\end{proposition}
Using this we can prove that operators close to any invertible operator are invertible, where the closeness depends on how large $\norm{T^{-1}}$ is.
\begin{corollary}
	The open operators are an open set of $\mathcal{L}(E)$ for a Banach space $E$.
\end{corollary}
\begin{proof}
	Let $S\in\mathcal{L}(X)$  with $\norm{T-S}<1/\norm{T^{-1}}$, then it holds that
	\begin{equation*}
		\norm{ST^{-1}-Id}=\norm{(S-T)T^{-1}}\leq\norm{S-T}\norm{T^{-1}}<1
	\end{equation*}
	This proves that $ST^{-1}$ is invertible and thus, since $T$ is invertible so is $S$.
\end{proof}
\subsection{Specter of a linear operator}
\begin{definition}
	Let $T\in\mathcal{L}(E)$ with $E$ a Banach space, then we say that the \emph{specter of T} is
	\begin{equation*}
		\sigma(T):=\{\lambda\in\mathbb{K}: T-\lambda I \text{ is not invertible}\}
	\end{equation*}
\end{definition}
\begin{definition}
	Let $T\in\mathcal{L}(E)$ with $E$ a Banach space, then we say that the \emph{eigenvalues of T} are the $\lambda$ such that $T-\lambda I$ is not injective. We call the set of eigenvalues the \emph{pointwise specter} of $T$
	\begin{equation*}
		\sigma(T):=\{\lambda\in\mathbb{K}: T-\lambda I \text{ is not invertible}\}
	\end{equation*}
\end{definition}
For example the spectrum of $T=Id$ is $\sigma(T)=\{1\}$. Note that, by definition, the pointwise spectrum is within the spectrum.
\begin{proposition}
	Let $T\in\mathcal{L}(E)$, then $\sigma(T)$ is a closed subset in $\bar{B}(0,\norm{T})$
\end{proposition}
\begin{proof}
	Let $\lambda\notin \sigma(T)$, then $T-\lambda I$ is invertible so, since invertible operators are open set, so is  $T-(\lambda+\mu) I$ for small $\mu$. This shows that $\sigma(T)$ is closed. Furthermore, if $\lambda>\norm{T}$ then
	\begin{equation*}
		T-\lambda I=\lambda \qty(\frac{T}{\lambda}-I).
	\end{equation*}
	Since $\norm{T\lambda}<1$ this is invertible.
\end{proof}
\begin{definition}
	The spectral radius of $T$ is defined as
	\begin{equation*}
		\rho(T):=\sup\{\abs{\lambda:\lambda\in\sigma(T)}\}
	\end{equation*}
\end{definition}
\begin{proposition}
	Let $T:E_1\to E_2$ be an operator between two Banach spaces such that
	\begin{equation*}
		\norm{Tx}\geq c\norm{x}\quad\forall x\in E_1.
	\end{equation*}
	Then $T:X\to Im(T)$ is a homeomorhphism.
\end{proposition}
\begin{proof}
	$T$ is injective by the condition, it's image is closed as if $T(x_n)$ converges so does $x_n$ by the condition. As a result, $T:E_1\to Im(T)$ is a bijective operator between two Banach spaces so it is invertible by the homeomorphism theorem.
\end{proof}
\begin{proposition}
	Let $T$ be a non-zero compact operator on a Banach space, then nonzero elements $\lambda\in\sigma(T)$ are also eigenvectors with finite dimensional eigenspace $ker(T-\lambda I)$.
\end{proposition}
\begin{proof}
	By hypothesis $T-\lambda I$ is compact. If $\lambda$ is not an eigenvalue then $T-\lambda I$ is injective, so equivalently, by the Fredholm alternative it is surjective and thus, by the homeomorphism theorem, invertible. This contradicts that $\lambda$ is in the spectrum
\end{proof}
\section{Self-adjoint operators}
\begin{proposition}
	Let $T\in\mathcal{L}(H)$with $H$ a Hilbert space, then
	\begin{equation*}
		\ker(T)=(\Im T^*)^\perp
	\end{equation*}
\end{proposition}
\begin{proof}
	Let $e\in \ker(T)$, then $\br{e,T^*v}=0$. The other inclusion is due to $H^\perp =0$.
\end{proof}
\begin{proposition}
	Let $T$ be a self-adjoint operator on a Hilbert space, then its spectrum is non-empty (and contains $\norm{T}$ or $-\norm{T}$)
\end{proposition}

\begin{proposition}
	Let $T\in\mathcal{L}(H)$ be compact and self-adjoint, then if $D=\sigma_P\setminus\{0\}$ is the set of non-zero eigenvalues we have that
	\begin{equation*}
		H=\operatorname{ker}(T) \oplus \overline{\bigoplus_{\lambda \in D} \operatorname{ker}(T-\lambda I)}
	\end{equation*}
	Where $\operatorname{ker}(T-\lambda I)$ are finite dimensional spaces orthogonal amongst each other.
\end{proposition}
\begin{proof}
	Firstly we have that, since $T$ is compact, $\ker(T-\lambda I)$ is finite dimensional, and since it is self-adjoint they are orthogonal. Write $E$ for the term on rhs, by self-adjointness also
	\begin{equation*}
		\ker{T}\subset (\ker(T-\lambda I))^\perp
	\end{equation*}
	for all $\lambda\in D$ so $\ker{T}\subset E^\perp$ . To see the other inclusion we have that $\restr{T}{E^\perp}$ is compact and self adjoint, so if it is non-zero it has some nonzero eigenvalue ($\norm{T}$ or $-\norm{T}$) but all the non-zero eigenvalues are in $E$ not in $E^\perp$. So $E^\perp\subset\ker{T}$. As a result $E^\perp=\ker{T}$ so, since $E$ is a closed vector space,
	\begin{equation*}
		H=E^\perp\oplus {E^\perp}^\perp=\ker(T)\oplus E
	\end{equation*}
\end{proof}
\begin{theorem}[Hilbert Schmidt]\label{Hilber-Schmidt}
	Let $T\in\mathcal{L}(H)$ be a compact, self adjoint operator, then it diagonalizes. That is, there exists an orthonormal basis $e_i$ of eigenvectors with eigenvalues $\lambda_i\in\R$. Furthermore,
	\begin{equation*}
		Tx=\sum_{i\in I} \lambda_i\br{x,e_i}e_i\quad\forall x\in H.
	\end{equation*}
\end{theorem}
\begin{proof}
	We know that if $\sigma_P$ is the set of eigenvalues, then
	\begin{equation*}
		H= \overline{\bigoplus_{\lambda \in \sigma_P} \operatorname{ker}(T-\lambda I)}
	\end{equation*}
	where all the appearing spaces are orthogonal. It suffices to choose an orthonormal basis in each of $\operatorname{ker}(T-\lambda I)$.
\end{proof}
In the finite dimensional case we have that if $T$ is self adjoint and non-negative then there exists a diagonal matrix $D$ and a unitary matrix $U$ with
\begin{equation*}
	T=UDU^\dagger=(U\sqrt{D}U^\dagger)(U\sqrt{D}U^\dagger)
\end{equation*}
That is, $T$ has a square root which is itself non-negative and positive definite. The same result holds for separable Hilbert spaces.
\begin{theorem}
	Let $T$ be non-negative and self-adjoint on a separable Hilbert space, then there exists a unique non-negative self adjoint operator $\sqrt{T}$ such that $T=\sqrt{T}\sqrt{T}$.
\end{theorem}
This follows from the spectral theorem or representation of $C$ star algebras see \cite{lototsky2017stochastic} page 217. We note that given any operator $T\in \Ll(U,H)$ the operator $TT^*$ is non-negative and self-adjoint. As a result we can make the following definition.
\begin{definition}
	Given a linear operator $T$ between Hilbert spaces we define
	\begin{equation*}
		\abs{T}:=\sqrt{T T^*}  .
	\end{equation*}

\end{definition}

\section{Trace and Hilbert Schmidt operators}
We consider in this section $U,H$ to be separable Hilbert spaces, though much would remain valid for complex Hilbert spaces which are not necessarily separable with minimal adjustments.
\begin{definition}
	A linear operator $Q\in L(U)$ is said to be non-negative if
	\begin{equation*}
		\br{Qu,u}\geq 0\quad\forall u\in U.
	\end{equation*}
\end{definition}
\begin{definition}
	A linear operator $Q\in L(U)$ is said to be symmetric (or self-adjoint) if
	\begin{equation*}
		\br{Qu,v}=\br{u,Qv}\quad\forall u,v\in U.
	\end{equation*}
\end{definition}
\begin{definition}
	A partial isometry is a linear map $Q:U\to H$ such that $Q$ is an isometry on $Ker(Q)^\perp$.
\end{definition}
\begin{theorem}[Polar Theorem]
	Let $Q:U\to H$ be a linear operator between Hilbert spaces, then there is a unique partial isometry $T$ such that
	\begin{equation*}
		Q=T\abs{Q};\quad \ker(T)=\ker(Q).
	\end{equation*}
	Additionally $T^*Q=\abs{Q}$.
\end{theorem}
\begin{proof}
	Since $\norm{T}=\norm{\abs{T}}$ we may define $T(\abs{Q}x)=Qx$ and  $Ty=0$ for  $y_\in \ker{Q}$. This can then be extended continuously to $U=\overline{\Im(\abs{Q})}\oplus \Im(\abs{Q})^\perp$   See \cite{murphy2014c} page 51.
\end{proof}

The above theorem is the analogous of the fact that a complex number can be written as
\begin{equation*}
	z=e^{i\arg(z)}\abs{z}.
\end{equation*}


\begin{definition}
	A linear operator $Q\in L(U\to H)$ is said to have finite trace if for every orthonormal basis $\{e_k\}_{k=1}^\infty \subset  U$
	\begin{equation*}
		\norm{Q}_1:=\sum_{k\in\mathbb{N}}\br{\abs{Q}e_k,e_k}<\infty.
	\end{equation*}
	It is also said that $Q$ is trace class or nuclear. We write the space of such functions as $\mathcal{L}_1(U)$.
\end{definition}
Despite the name, we cannot define the trace of a trace class operator $Q$ unless  $U=H$. In this case we say that the trace of $Q$ is the quantity
\begin{equation*}
	Tr(Q):=\sum_{n=0}^{\infty} \br{Q e_n,e_n}.
\end{equation*}
We note that $Tr(Q)\leq \norm{Q}_1$ and that is is not enough for the trace of $Q$ to exist for $Q$ to be trace class as the sum may convergence but not absolutely. In the literature one may find many other equivalent definitions for trace class operators. We include the following list below which may be found in \cite{lototsky2017stochastic} page $92$.
\begin{proposition} Given two Hilbert spaces (not sure if separable would be necessary...) $U,H$ and a linear operator  $Q\in L(U,H)$ the following are equivalent.
	\begin{enumerate}
		\item $Q$ is trace class.
		\item $\sqrt{|Q|} $ is a Hilbert Schmidt operator.
		\item For all orthonormal basis of $U,H$ we have $\sum_{n=0}^{\infty} \br{Qe_n,v_n}<\infty$.
		\item $Q$ is compact and  $\sum_{n=0}^{\infty} \lambda _n<\infty$ where $\lambda _n$ are the eigenvalues of $\abs{Q}$.
		\item $Q$ is nuclear, that is there exists  $\lambda _n \in \R,\ell_n \in H^*$ and $y_n \in H$ bounded sequences such that
		      \begin{equation*}
			      T(x)=\sum_{n=0}^{\infty} \lambda _n\ell_n(x)y_n \quad\forall x\in H.
		      \end{equation*}
		\item $Q^*$ is nuclear.
		\item $\sum_{n=0}^{\infty} \norm{Qe_n}<\infty$ for some orthonormal basis.

	\end{enumerate}
\end{proposition}

\begin{definition}
	We write $\mathcal{L}_1^+(U)$ for the space of trace class, positive semi-definite, symmetric operators.
\end{definition}
Though in infinite dimension this definition could depend on the basis it will not do so for the class of linear operators we are interested in. This is because due to the following result all these operators are nuclear.
\begin{proposition}[Hilbert Schmidt for $\mathcal{L}_1^+$]
	If $Q \in \mathcal{L}_1^+(U)$ then there exists an orthonormal basis $e_{k}, k \in \mathbb{N}$, of $U$ such that
	$$
		Q e_{k}=\lambda_{k} e_{k}, \quad \lambda_{k} \geq 0\quad \forall k \in \mathbb{N}.
	$$
\end{proposition}
\begin{proof}
	By definition of $mathcal{L}_1^+(U)$ we have that $Q$ is self-adjoint and compact (as it is nuclear).
	As a result we may apply the Hilbert Schmidt theorem \ref{Hilber-Schmidt} to obtain that
	\begin{equation*}
		Q x=\sum_{k\in\N}\lambda_{k} \br{x,e_{k}}.
	\end{equation*}
	Finally, $\lambda_k\geq 0$ as $Q$ is positive semi-definite.
\end{proof}
We fix $U,H$ to be separable Hilbert spaces
\begin{definition}
	Let $e_k$ be an orthonormal basis of $U$. Then $A\in L(U,H)$ is said to be a \emph{Hilbert-Schmidt} operator if
	\begin{equation*}
		\norm{A}_{L_2(U,H)}:=\sum_{k\in\mathbb{N}}\br{Ae_k,Ae_k}<\infty.
	\end{equation*}
\end{definition}
\begin{proposition}
	The space of Hilbert-Schmidt operators $L_2(U,H)$ is a separable Hilbert space of compact operators with the inner product
	\begin{equation*}
		\br{A,B}:=\sum_{k\in\mathbb{N}}\br{Ae_k,Be_k}.
	\end{equation*}
	Furthermore the inner product is independent of the choice of basis $e_k$ of $U$.
\end{proposition}
\begin{proof}
	The completeness follows from that of the analogously defined $L_1(U,H)$ \cite[Corollary 16.25, p.154]{hirzebruch1971einfuhrung} and Fatou's lemma.\\
	\\
	By Parseval's identity given a basis $f_k$ of $H$ it holds that
	\begin{equation*}
		\sum_k \norm{Ae_k}^2=\sum_k\sum_j\abs{\br{Ae_k,f_j}}^2=\sum_j\sum_k\abs{\br{A^*f_j,e_k}}^2=\sum_j \norm{A^*f_j}^2
	\end{equation*}
	This proves the last part of the proposition as $\norm{T}=\norm{T^*}$. To prove that it is separable we show that
	\begin{equation*}
		f_j\otimes e_k:= \br{e_k,\cdot}f_j
	\end{equation*}
	is an orthonormal basis (the orthonormality is a calculation) and that is is a basis follows from the fact that $\br{A, f_j\otimes e_k}=\br{f_j,Ae_k}$. So if all of these terms are $0$ then $A=0$ as
	\begin{equation*}
		Ax=\sum_{k,j} \br{x,e_k}\br{Ae_k,f_j}f_j=\sum_{k,j} \br{x,e_k}\br{A, f_j\otimes e_k}f_j.
	\end{equation*}
\end{proof}
\begin{proposition}
	If $A\in L^2(U,H)$ then it is also compact
\end{proposition}
\begin{proof}
	This follows from the fact that by taking $A_n:=A\circ \Pi_n$ where $\Pi_n$ is the projection onto the finite dimensional space generated by $\{e_1,..,e_n\}$
	\begin{equation*}
		\norm{Ax-A_nx}=\norm{\sum_{n=0}^\infty\br{x,e_n}Ae_n}\leq \norm{x}^2\norm{A}_{L_2(U,H)}
	\end{equation*}
	and the completeness of the space of compact operators to Banach spaces.
\end{proof}
\begin{proposition}
	Given $A\in L_2(U,H)$ and $T_1\in L(H_1,H),T_2\in L(H,H_2)$ with $H_1,H_2$ separable Hilbert spaces. Then we have that
	\begin{itemize}
		\item $\norm{A}_{L_2(U,H)}=\norm{A^*}_{L_2(H,U)}$ where $A^*$ is the adjoint of $A$.
		\item $A\circ T_1\in L_2(U,H_2)$ and $T_2\circ A\in L_2(U,H_2)$.
	\end{itemize}
\end{proposition}
\begin{proposition} Let $\Sigma\in L(U,U)$ be nonnegative and symmetric. The there exist a unique element $\Sigma^\frac{1}{2}$ verifying that
	\begin{equation*}
		\Sigma^\frac{1}{2}\circ\Sigma^\frac{1}{2}=\Sigma.
	\end{equation*}
	Furthermore, if $\Sigma$ has finite trace then $\Sigma^\frac{1}{2}\in L^2(U,U)$ and $\norm{\Sigma^\frac{1}{2}}_{L_2(U,U)}^2=tr(\Sigma)$.
\end{proposition}
The proof can be found in \cite[p.196]{reed1972methods}.
\section{Reproducing kernel}
In this section we will consider all vector spaces to be complex.
\begin{definition}
	A reproducing kernel space is a Hilbert space $H\subset \C^S$ where $S$ is some set and such that  point evaluation $$\ell _s(f):=f(s),\quad f\in H$$ is continuous for all $s\in S$
\end{definition}
For example the spaces $L^2(\R^d)$ do not fall into this category as pointwise evaluation is not even well defined. That is, unless we consider $S=L^2(\R^d)$ with pointwise evaluation defined as
\begin{equation*}
	f(s):=\br{f,s},\quad\forall s\in S.
\end{equation*}
In this case we would obtain that $L^2(\R^d)$ is a reproducing kernel space over itself with reproducing kernel $K(f,\cdot )=f.$ This construction can be used to view any Hilbert space as a reproducing kernel space over itself with kernel the ``identity''. To five another example, by Sobolev embedding theory, $H^s(\R^d)$ are reproducing kernel spaces for $s>\frac{d}{2}$.
\begin{definition}
	A real valued function $K:S\times S$ is said to be a positive-definite  Kernel if  $\{K(t_i,t_j)\}_{i,j=1}^n$ is a Hermitian, non-negative matrix for all $t_i \in S,n \in \N$.
\end{definition}
For example the covariance function $K(t,s)=Cov(X(t),X(s))$ of a real valued process is a kernel.
\begin{theorem}[Existence and uniqueness of reproducing kernels and their spaces]
	Given a reproducing kernel Hilbert space $H$ there exists a unique kernel $K_H$ called the \emph{reproducing kernel} of $H$ such that
	\begin{equation*}
		f(s)=\br{f,K_H(s,\cdot )},\quad\forall f\in H.
	\end{equation*}
	Furthermore, given any positive-definite kernel $K$ their exists a reproducing kernel space $H_K$ such that $K$ is the reproducing kernel of $H_K$.
\end{theorem}
\begin{proof}
	We first prove the existence and uniqueness of $K_H$, by Riesz's representation theorem, for each $s\in S$ there exists $g_s\in H$ such that
	\begin{equation*}
		f(s)=\br{f,g_s}\quad\forall f\in H.
	\end{equation*}
	Let us define $K_H(t):=g_s(t)$, the defining property is verified by construction and it remains to see that $K_H$ is a positive definite
	kernel. This follows from the equality
	\begin{equation}\label{rep kernel}
		K_H(s,t)=\br{K_H(s,\cdot ),K_H(t,\cdot )}.
	\end{equation}
	To prove the existence of $H_k$ we set
	\begin{equation*}
		\quad H_{K,0}:=Span(\{K(s,\cdot ):s\in S\});\quad \br{\sum_{j=0}^{n}K(s_j,\cdot ),\sum_{k=0}^{m} K(t_k,\cdot )}_{H_{K,0}}:=\sum_{j=0}^{n}\sum_{k=0}^{m}K(s_j,t_k).
	\end{equation*}
	We note that the above defines a inner product by the symmetry and positivity condition on $K$ and that pointwise evaluation is continuous by construction and Cauchy Schwartz. All that is left is to take the completion  $H_K:=\overline{H_{k,0}}$ as it is a verification that $K$ is the reproducing kernel of  $K_H$.
\end{proof}
The equality \eqref{rep kernel} motivates the name reproducing Kernel. Another equality of note, which can be easily derived from the above is that, given an orthonormal basis $e_k$ of $H$
\begin{equation*}
	K_H(s,t)=\sum_{n=0}^{\infty} e_n(s)\overline{e_n(t)}.
\end{equation*}

Given any topological vector space $(V,\Bb(V),\mu )$ whose measure allows for the existence of second moments, we can construct a positive definite kernel on $V'$ as
\begin{equation*}
	C_\mu (\ell ,h):=\int_{V}\ell (v) \overline{h(v)}\mu (dv)-\int_{V}\ell (v) \mu (dv)\overline{\int_{V}h(v)\mu (dv)}.
\end{equation*}
We call this the \emph{covariance operator (kernel)} associated with $\mu $. By setting $S=V'$ we may apply the previous to deduce that there exists a Hilbert space $H_\mu $ whose reproducing kernel is $C_\mu $. We call this space the \emph{reproducing kernel Hilbert space of $\mu $}. If $\mu $ is the distribution of some $V$ valued random variable $X$ then we also say that $H_\mu $ is the  \emph{reproducing kernel Hilbert space of $X$}.\\
\\
Alternatively, we can also view  $C_\mu $ as a function from $V'\to \overline{V'}'$. Where given a vector space $E$ we denote the space of antilinear maps by   $\overline{E}'$ In the case where $V$ is a Hilbert space $H$ we can identify $H$ with both $H'$ and $\overline{H'}'$. Through these identifications we deduce for each $h\in H$ the existence of  some $h_\mu \in H$ such that
$C_\mu (h,\cdot )=\br{h_\mu,\cdot  }$. That is
\begin{equation*}
	C_\mu (h,x)=\br{h_\mu,x},\quad\forall h,x \in H .
\end{equation*}
By another abuse of notation, using the previous identifications we can consider
\begin{align*}
	C_\mu : H & \longrightarrow H             \\
	h         & \longmapsto C_\mu (h) = h_\mu
	.\end{align*}
That is, to gather all the notation together
\begin{equation*}
	C_\mu (\br{\cdot ,h},\br{\cdot ,x})=C_\mu (h,x)=\br{C_\mu (h),x}\quad\forall h,x\in H.
\end{equation*}

\begin{theorem} Let $H$ be a separable Hilbert space and identify  $H$ with $H'$, then:
	\begin{enumerate}
		\item Given a Gaussian measure $\mu $ on a Hilbert space $(H,\Bb(H))$, its covariance operator is trace class. That is, $C_\mu \in \Ll_1^+(H)$.
		\item Given $K\in \Ll_1^+(H)$ there exists a Gaussian measure $\mu $ on $(H,\Bb(H))$ such that $C_\mu(u,v)=\br{Ku ,v}$.
	\end{enumerate}
\end{theorem}
\begin{proof}
	\begin{itemize}
		\item Consider an orthonormal basis $e_n$ of $H$ (which we recall we are identifying with $H'$), then we have that
		      \begin{equation*}
			      \sum_{n=0}^{\infty} \br{C_\mu (e_n),e_n}_H=\sum_{n=0}^{\infty} C_\mu (\br{\cdot ,e_n},\br{\cdot ,e_n})_H=\int_{H}\norm{v}^2 \mu (dv)<\infty.
		      \end{equation*}
		      Where the last equality is due to Fernique's theorem,which says that Gaussian measure have exponential decrease.
		\item By theorem .... we can diagonalize $K$ to obtain a orthonormal basis  $e_n$ with  $Ke_n=\lambda e_n$. By theorem we can build a probability measure $\mathbb{P}$ on $(H,\Bb(H))$ together with a sequence $G_n$ of iid unit Gaussian vectors. Let us set
		      \begin{equation*}
			      \mu :=\mathbb{P}_X;\quad X=\sum_{n=0}^{\infty} \sqrt{\lambda _n} G_ne_n .
		      \end{equation*}
		      Then we have that $\mu $ is a Gaussian measure and, by the transfer theorem and independence and normality of $G_n$
		      \begin{multline*}
			      C_\mu (u,v)=\int_{H}\br{u,h}\overline{\br{v,h}} d\mathbb{P}_X=\sum_{n,m=0}^{\infty}\sqrt{\lambda_n}\sqrt{\lambda_m}  \br{u,e_n}\overline{\br{v,e_m}}\E[G_nG_m]\\
			      =\sum_{n=0}^{\infty}\lambda_n\br{u,e_n}\overline{\br{v,e_n}}=\br{Ku,v}.
		      \end{multline*}

	\end{itemize}
\end{proof}
We now have a relationship between operators in $\Ll_1^+(H)$ and Gaussian measures. A natural question is whether this relationship is bijective. To do so we introduce the Fourier transform. For Gaussian measures on separable Banach spaces we have the following
\begin{proposition}
	Let $E$ be a separable Banach space, then $\mu $ is a Gaussian measure on $E$ iff for every linear function  $\ell :E\to\R$
	\begin{equation*}
		\hat{\mu }(\ell )=e^{i\ell(m)-\frac{1}{2}C_\mu (\ell ,\ell )}.
	\end{equation*}
	Where
	$		m:=\int_{E}x \mu (dx).
	$
\end{proposition}
\begin{proof}
	By theory of $1$-dimensional Gaussian random variables we have that  $\ell ^*\mu $
	is a Gaussian measure if and only if
	\begin{equation*}
		\hat{\mu }(\ell )=\int_{E}x \ell^*\mu (dx)=\varphi_{\ell^*\mu}(1)=e^{ia -\frac{1}{2}\sigma^2} .
	\end{equation*}
	Where, by the linearity of the Bochner integral,
	\begin{align*}
		a      & =\int_{E}x \ell ^*\mu.  (dx)=\int_{E}\ell(x)\mu(dx)=\ell(m)                      \\ .
		\sigma & =\int_{E}x^2 \ell ^*\mu  (dx)=\int_{E}\ell(x)\ell (x)\mu(dx)=C_\mu (\ell ,\ell).
	\end{align*}
\end{proof}
Furthermore, the Fourier transform uniquely characterizes the measure, as a result we obtain that a Gaussian measure on  a separable Banach space $E$ is uniquely characterized by its mean and covariance operator. However, note that  there may in general be infinite Gaussian measures on $E$ with the same mean and covariance operator. In fact, in the previous theorem we constructed one for each choice of orthonormal basis.
\section{Construction of the stochastic integral}
We fix $U,H$ to be separable Hilbert spaces and $E$ a separable Bach space.
The way to construct the Stochastic integral is as follows
\begin{enumerate}
	\item Construct for elementary processes $Int:\mathcal{E}\to\mathcal{M}_T^2(H)$.
	\item It is a isometry so it extends uniquely and isometrically to $\Bar{\mathcal{E}}$.
	\item Characterise $\bar{\mathcal{E}}$.
\end{enumerate}
In the case where $U=\R^n,H=\R^m$ we have that elementary processes would be defined piece wise in time as some matrices in $\R^{m\times n}$. In this case we have similarly that
\begin{definition}
	[Elementary Process] An $L(U, H)$-valued process $\Phi(t)$, on $(\Omega, \mathcal{F}, P)$ with respect to $\mathcal{F}_{t}$, is said to be elementary if there exist $0=t_{0}<\cdots<t_{k}=T, k \in \mathbb{N}$, such that
	$$
		\Phi(t)=\sum_{m=0}^{k-1} \Phi_{m} 1_{( t_{m}, t_{m+1}]}(t), \quad t \in[0, T]
	$$
	Where $\Phi_m:\om\to L(U,H)$ is measurable between $\mathcal{F}_{t_m}$ and the Borel $\sigma$-algebra on $L(U,H)$ and takes only a finite amount of values. We write the space of these processes by $\mathcal{E}=\mathcal{E}(\om,\mathcal{F},U,H)$.
\end{definition}
\begin{definition}[Stochastic integral for elementary processes]
	Given $\Phi\in\mathcal{E}$ and a $U$ valued $\Sigma$ Wiener process we define its stochastic integral as
	\begin{equation*}
		Int(\Phi)(t)\equiv \int_0^t\Phi(s)dW(s):=\sum_{m=0}^{k-1} \Phi_{m}(W(t\wedge t_{m+1})-W(t_m\wedge t))
	\end{equation*}
\end{definition}
We note that if $t<t_m$ then $t\wedge t_{m+1}=t_m\wedge t$ so the above definition corresponds to transforming the increments of $W$ up to time $t$ using $\Phi$.
\begin{proposition}
	Given $\Phi\in\mathcal{E}$ and a $U$ valued $\Sigma$ Wiener process
	\begin{equation*}
		\int_0^t\Phi(s)dW(s)\in\mathcal{M}_T^2(H)
	\end{equation*}
\end{proposition}
\begin{proof}
	The continuity in $t$ is clear as $W(t)$ is continuous and so are $\Phi_m$. Square integrability follows from this property holding for $W(t)$ and the fact that, since $\Phi_m$ takes only a finite amount of values in $L(U,H)$, the norm $\Phi_m(\omega)$ is bounded. The fact that it is a Martingale is a technical calculation using the linearity of the integral and that $\Phi_m$ takes only a finite amount of values in $L(U,H)$.
\end{proof}
\begin{proposition}[Ito's isometry for elementary processes]\label{ito elementary}
	Given $\Phi\in\mathcal{E}$ it holds that
	\begin{equation*}
		\left\|\int_{0}^\cdot \Phi(s) d W(s)\right\|_{\mathcal{M}_{T}^2(H)}^2=E\left(\int_{0}^{T}\left\|\Phi(s) \circ \Sigma^{\frac{1}{2}}\right\|_{L_2(U,H)}^2 d s\right)=:\|\Phi\|_{\mathcal{E}}^2
	\end{equation*}
\end{proposition}
The proof is a very technical calculation. We then identify to elementary processes if the seminorm $\norm{\cdot}_T$ is equal. We note that this does not necessarily implt that the processes are equal $dt_{[0,T]}\otimes\mathbb{P}$ almost everywhere. But rather that they correspond on $\Sigma^\frac{1}{2}(U)$, $dt_{[0,T]}\otimes\mathbb{P}$ almost everywhere.

\begin{corollary}
	The transformation
	\begin{equation*}
		int:\mathcal{E}\to \mathcal{M}_T^2(E).
	\end{equation*}
	is an isometric linear transformation
\end{corollary}
We now characterize $\bar{\mathcal{E}}$. We need the following defintions
\begin{definition}
	Let $H'$ be a separable Hilbert space and define
	\begin{align*}
		\mathcal{P}_{T} & :=\sigma\Big(\big\{(s, t] \times F_{s} :0 \leq s<t \leq T, F_{s} \in \mathcal{F}_{s}\big\} \cup\big\{\{0\} \times F_{0} :F_{0} \in \mathcal{F}_{0}\big\}\Big) \\
		                & =\sigma(Y: \Omega_{T} \rightarrow \mathbb{R} :Y \text { is left-continuous and adapted to }
		\mathcal{F}_{t}, t \in[0, T]) .
	\end{align*}
	Then $Y:\Omega\to H'$ is said to be $H'$ predictable if it is $\mathcal{P}_T\to\mathcal{B}(H')$ measurable.
\end{definition}
\begin{definition}
	Let $H$ be a separable Hilbert space and $\Sigma$ non-negative, symmetric, with finite trace. Then we define the separable Hilbert space
	\begin{equation*}
		L_2^0:=L_2(U_0,H);\quad (U_0,\br{\cdot,\cdot}_0):=\qty(\Sigma^{\frac{1}{2}}(U),\br{\Sigma^{-\frac{1}{2}}\cdot,\Sigma^{-\frac{1}{2}}\cdot}_U).
	\end{equation*}
	Which is the space of Hilbert Schmidt operators between $U_0$ and $H$.
\end{definition}
It can be shown that
\begin{equation*}
	\norm{f}_{L_{2}^{0}}=\norm{f\circ \Sigma^\frac{1}{2}}_{L_2(U\to H)}.
\end{equation*}
As a result, if we define
\begin{equation*}
	\|\Phi\|_{T}=\left(E\left(\int_{0}^{T}\|\Phi(s)\|_{L_{2}^{0}}^{2} \mathrm{~d} s\right)\right)^{\frac{1}{2}}.
\end{equation*}
Then, by the definition in \ref{ito elementary}, $\norm{\Phi}_T=\norm{\Phi}_\mathcal{E}$ for all $\Phi\in\mathcal{E}$. Furthermore, we can prove the following.
\begin{theorem}
	The completion $\bar{\mathcal{E}}$ of the elementary processes is given by
	\begin{align*}
		\mathcal{N}_{W}^{2}(0, T ; H) & :=\left\{\Phi:[0, T] \times \Omega \rightarrow L_{2}^{0} :\Phi \text { is predictable and }\|\Phi\|_{T}<\infty\right\} \\
		                              & =L^{2}\left([0, T] \times \Omega, \mathcal{P}_{T}, \mathrm{~d} t \otimes P ; L_{2}^{0}\right) .
	\end{align*}
	Let $E$ be a separable Banach space, then $\mu $ is a Gaussian measure on $E$ iff for every linear function  $\ell :E\to\R$
	\begin{equation*}
		\hat{\mu }(\ell )=e^{i\ell(m)-\frac{1}{2}C_\mu (\ell ,\ell )}.
	\end{equation*}
	Where
	$    	m:=\int_{E}x \mu (dx).
	$
\end{theorem}
\bibliography{biblio.bib}
\end{document}
