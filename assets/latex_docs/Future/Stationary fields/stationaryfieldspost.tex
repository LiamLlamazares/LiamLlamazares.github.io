\documentclass[12pt]{article}
\special{papersize=3in,5in}
\usepackage[utf8]{inputenc}
%PACKAGES
\usepackage{CJKutf8}
\usepackage[colorlinks = true,
	linkcolor = blue,
	urlcolor  = black,
	citecolor = blue,
	anchorcolor = blue]{hyperref}
\usepackage[T1]{fontenc}
\makeatletter
\def\ps@pprintTitle{%
	\let\@oddhead\@empty
	\let\@evenhead\@empty
	\let\@oddfoot\@empty
	\let\@evenfoot\@oddfoot
}
\usepackage{amssymb,amsmath,physics,amsthm,xcolor,graphicx}
\usepackage[shortlabels]{enumitem}
\newtheorem{observation}{Observation}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{example}{Example}
\newcommand{\red}[1]{{\color{red}#1}}
\usepackage[colorlinks = true,
	linkcolor = blue,
	urlcolor  = black,
	citecolor = blue,
	anchorcolor = blue]{hyperref}
\usepackage{cleveref}
\bibliographystyle{elsarticle-num}
\newcommand{\A}{\mathbb{A}}\newcommand{\C}{\mathbb{C}}\newcommand{\E}{\mathbb{E}}\newcommand{\F}{\mathbb{F}}\newcommand{\K}{\mathbb{K}}\newcommand{\LL}{\mathbb{L}}\newcommand{\M}{\mathbb{M}}\newcommand{\N}{\mathbb{N}}\newcommand{\PP}{\mathbb{P}}\newcommand{\Q}{\mathbb{Q}}\newcommand{\R}zzzzz\newcommand{\T}{{\mathbb T}}\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Ww}{\mathcal{W}}\newcommand{\Aa}{\mathcal{A}}\newcommand{\Bb}{\mathcal{B}}\newcommand{\Cc}{\mathcal{C}}\newcommand{\Ee}{\mathcal{E}}\newcommand{\Ff}{\mathcal{F}}\newcommand{\Gg}{\mathcal{G}}\newcommand{\Hh}{\mathcal{H}}\newcommand{\Kk}{\mathcal{K}}\newcommand{\Ll}{\mathcal{L}}\newcommand{\Mm}{\mathcal{M}}\newcommand{\Nn}{\mathcal{N}}\newcommand{\Pp}{\mathcal{P}}\newcommand{\Qq}{\mathcal{Q}}\newcommand{\Rr}{{\mathcal R}}\newcommand{\Ss}{{\mathcal S}}\newcommand{\Tt}{{\mathcal T}}\newcommand{\Zz}{{\mathcal Z}}\newcommand{\Uu}{{\mathcal U}}
\newcommand{\W}{{\mathcal W}}
\newcommand\restr[2]{{\left.\kern-\nulldelimiterspace #1\vphantom{\big|} \right|_{#2}}}
\newcommand{\br}[1]{\left\langle#1\right\rangle}
\pagestyle{empty}
\setlength{\parindent}{0in}

\begin{document}
\begin{CJK*}{UTF8}{gbsn}
	\title{Stationary fields, spectral theor}
	\author{Liam Llamazares}
	\date{10-14-2022}
	\maketitle
	\section{ Three line summary }
	\begin{itemize}
		\item Stationary fields are fields that, to second order are stationary and they have some nice theory:
		      item Stationary fields covariance function is the Fourier transform of a positive finite measure called the spectral measure.
		\item Stationary fields are a random integral
		\item Stationary fields a rise as solutions to differential equations.
	\end{itemize}
	\section{Why should I care?}

	\section{Notation and preliminaries}
	We recall our (somewhat controversial) convention of defining as Fourier transform and inverse Fourier transform (with all the future constants that this may imply) as
	\begin{equation*}
		\hat{f}(\omega):=\frac{1}{(2\pi)^d}\int_{\R^d}f(x)e^{-i\omega\cdot x} dx;\quad \check{f}(\omega):=\int_{\R^d}f(x)e^{i\omega\cdot x} dx
	\end{equation*}
	We recall that $\check{\hat{f}}=\hat{\check{f}}=f$ and Plancherel's theorem now reads
	\begin{equation*}
		\br{f,g}_{L^2(\R^d)}=\frac{1}{(2\pi )^d}\br{\check{f},\check{g}}_{L^2(\R^d)}, \quad\forall f,g\in L^2(\R^d).
	\end{equation*}
	We will consider a base probability space which we write $(\Omega,\Ff,\mathbb{P})$.
	We denote the \emph{Schwartz space} as
	\begin{equation*}
		\Ss(\R^d\to\C):=\left\{f\in \C^\infty(\R^d \to \C): \sup_{x_\in \R^d}\abs{\abs{x}^kD^\alpha f(x)}<\infty , \quad\forall k\in \N,\alpha \in \N^d\right\}.
	\end{equation*}
	We recall it's interpretation as the space of infinitely differentiable functions whose derivatives all decrease faster than the inverse of any polynomial and recall that $\Ss(\R^d\to\C)$ is closed under the Fourier transform (link own article).

	We also introduce the notation $\mathcal{D}(\R^d\to\C):=C_c^\infty(\R^d\to\C)$ for the space of infinitely differentiable functions of compact support valued in $\C$. Note that $\mathcal{D}(\R^d\to\C)$ is \emph{not} closed under the Fourier transform as the transform of a compactly supported function need not be compactly supported.

	Given a topological vector space $V$ we write  $V'$ for it's dual space
	\begin{equation*}
		V':=\{\phi\in C(V\to\R) \text{ such that } \phi \text{ is linear}   \}.
	\end{equation*}
	The Fourier transform of $\phi \in \Ss'(\R^d\to\C)$ is defined naturally by duality (that is pretending $\phi$ is a smooth function we're integrating against) as
	\begin{equation*}
		(\Ff\phi)(f):=\frac{1}{(2\pi)^d} \phi(\check{f});\quad (\Ff^{-1}\phi)(f):=(2\pi )^d\phi(\hat{f}) .
	\end{equation*}
	Note that by the closure of $\Ss(\R^d\to \C)$ under the Fourier transform $\Ff,\Ff^{-1}$ are well defined. Furthermore, by construction one has that $\Ff$ and $\Ff^{-1}$ are inverses of each other. To simplify the notation we commit a slight abuse of notation and also write $$\hat{\phi}:=\Ff\phi;\quad  \check{\phi}:= \Ff^{-1}\phi.$$
	Finally, we can also extend the derivative, this time both to $\phi\in\mathcal{S}'(\R^d\to\mathbb{C})$ and $\phi\in\mathcal{D}'(\R^d\to\mathbb{C})$ by defining
	\begin{equation*}
		\br{f,D^\alpha\phi}:=D^\alpha \phi(f):=\phi(D^\alpha f).
	\end{equation*}
	The motivation is once more by duality as the equation holds when $\phi$ means integrating against a smooth function.
	\section{What is a generalized field?}
	Welcome back everyone, today we're here to take it from where we left off in the previous post in which we studied the theory of stationary fields, the question now is what is a generalized field and how to generalize the previous results to stationary generalized fields (whatever that means). Let's start right off with the definition,
	\begin{definition}\label{gen field def}
		A generalized random field over a topological vector space $V$ is a collection of random variables  $\{\mathfrak{X}(f)\}_{f\in V}$ such that the following hold
		\begin{enumerate}
			\item \emph{Linearity}: $\mathfrak{X}(f+ag)=X(f)+aX(g)$ for all  $f,g\in V$ and $a\in \R$.
			\item \emph{Continuity}: If $f_n\to f\in V$ then we have convergence in probability $\mathfrak{X}(f_n)\xrightarrow{\mathbb{P}}\mathfrak{X}(f)$.
		\end{enumerate}
	\end{definition}
	Now, why would I ever define such a thing? It turns out that, knowingly or not, you've seen generalized fields many times before. For example the 1-dimensional white noise  $dW$ in any SDE
	\begin{equation*}
		dX(t)=a(X,t)d t  +b(X,t)dW(t),\quad t\in I.
	\end{equation*}
	Is a generalized field $\{dW(f)\}_{f \in V}$ where now $V=L^2(I)$ and we define $dW(f)$ to be the Ito integral of  $f$
	\begin{align*}
		dW(f)= \int_{I} f(t)dW(t)
		.\end{align*}
	A similar thing occurs for SPDEs. For example, a typical SPDE will look something like
	\begin{equation*}
		\Delta u=\dot{W}.
	\end{equation*}
	Where in this case we take $\dot{W}$ to be White noise on $V=L^2(\R^d)$  which (spoilers) is a generalized field and $\Delta $ , in typical analysis fashion, is viewed as a continuous operator, for example between  the Hilbert spaces, $$\Delta :H^2(\R^d)\to L^2(\R^d).$$ You might have noticed in the previous two examples that $V$ seems to always be a Hilbert space. However, though this is the common way of things, it is not a requirement. In fact, from now on we will set $V=\mathcal{D}(\R^d\to\C)$ or $V=\Ss(\R^d\to\C)$.\\
	\\
	As the name implies, every (square integrable) random field $X\in L^2(\R^d\times\Omega)$ can be viewed as a generalized random field by simply defining
	\begin{equation}\label{ftog}
		\mathfrak{X} (f):=\br{f,X}_{L^2(\R^d\to\C)}=\int_{\R^d}f(x)\overline{X(x)} dx, \quad\forall f\in V.
	\end{equation}
	This very conveniently is going to help us motivate what a stationary generalized field is. Suppose $X$ is a stationary field, then for $\mathfrak{X} $ as in   \eqref{ftog} we would have that, by Fubini and a change of variables
	\begin{multline}\label{stat0}
		\E[\mathfrak{X}(f)\overline{\mathfrak{X}(g)}]=\E\qty[\int_{\R^d}f(x)\overline{X(x)} dx\overline{\int_{\R^d}f(y)\overline{X(y)} dy}]\\=\int_{\R^d}\int_{\R^d}f(x)r(y-x)\overline{f(y)} dx dy=\int_{\R^d}\int_{\R^d}f(x+s)r(y-x)\overline{f(y+s)} dx dy\\=\int_{\R^d}\int_{\R^d}\tau_sf(x)r(y-x)\overline{\tau_sf(y)} dx dy=\E[\mathfrak{X}(\tau_sf)\overline{\mathfrak{X}(\tau_sg)}]\quad\forall s\in \R^d.
	\end{multline}
	Where $\tau_sf:=f(\cdot +s)$ is a translation by $s$.
	As a result, we define as follows
	\begin{definition}
		We say that a generalized field $\mathfrak{X}$ is stationary if
		\begin{equation*}
			\E[\mathfrak{X}(f)\overline{\mathfrak{X}(g)}]=\E[\mathfrak{X}(\tau_sf)\overline{\mathfrak{X}(\tau_sg)}]\quad\forall s\in \R^d.
		\end{equation*}

	\end{definition}
	Thus, every (square integrable) stationary field is automatically a generalized stationary field, pretty neat, huh? Essentially, we're saying that a generalized field is stationary if every translation acts as a unitary operator (in the $L^2(\Omega)$ norm) on $\mathfrak{X}$. The question now is how can we characterize such fields. Similarly to the last post (link), we're going to first need to define what we mean by a \emph{positive definite generalized function}. We recall that by an equivalent characterization for positive definite functions (link), a continuous function $r$ is positive definite if and only if for all smooth $f$ we have that
	\begin{equation*}
		\int_{\R^d}\int_{\R^d}f(x)r(y-x)f(y) dx dy\geq 0.
	\end{equation*}
	The above integral can also be written $\phi(f*f^*)$ where $\phi$ is integrating against $r$ and where $f^*(x):=\overline{f(-x)}$. Thus we give the following definition.
	\begin{definition}
		We say $\phi\in V'$ is positive definite if
		\begin{equation*}
			\phi(f*{f}^*)\geq 0\quad\forall f\in V.
		\end{equation*}
		Where $f^*(x):=\overline{f(-x)}$.
	\end{definition}
	Note that the above definition makes sense as, if $f\in V$ then also $f^*\in V$ and, by an integration under the integral sign, $V$ is closed under convolutions (we recall that we're taking $V=C_c^\infty(\R^d)$ or $V=\Ss(\R^d)$). Also note that the above definition is more general (hence the name) as in general $\phi$ need not be defined by the integral against some function $r$.

	In the non-generalized case we work with the Fourier transform of $r$. In the generalized case we do the same but work with the Fourier transform of  $\phi$. To this end we have the following definition and lemma.

	\begin{definition}
		An element $\phi\in V'$ is \emph{multiplicatively positive} if
		\begin{equation*}
			\phi(\abs{f}^2)\geq 0\quad\forall f\in V.
		\end{equation*}
	\end{definition}
	\red{Change in what follows all $\check{f}$ for  $\hat{f}$ with necessary changes on constants. Already changes $r$ and  $X$. Do on paper first and make sure you get right spectral density for white noise. Otherwise take off ocnjugar on $X$ and revert  $r$.}
	\begin{lemma}
		It holds that $\phi\in \Ss'(\R^d)$ is positive definite if and only if $\check{\phi}$ is multiplicative positive.
	\end{lemma}
	\begin{proof}
		We recall that the Fourier transform is invertible on $\Ss(\R^d\to\C)$ and $\Ss'(\R^d\to\C)$. Given $g\in \Ss(\R^d\to\C)$ we have that
		\begin{equation*}
			\phi(g*g^*)=(\Ff\check{\phi})(g*g^*)=\frac{1}{(2\pi)^d}(\check{\phi})(\Ff^{-1}(g*g^*))=\frac{1}{(2\pi)^{d}}(\check{\phi})(|\check{g}|^2))
		\end{equation*}
		Taking $g=\hat{f}$ shows the implication and setting $g=f$ proves the reciprocal, concluding the proof.
	\end{proof}
	Note that in this lemma we restricted to $V=\Ss'(\R^d\to\C)$, as opposed to allowing also $V=\mathcal{D}'(\R^d\to\C)$. This is necessary as the Fourier transform is only defined for the first of these spaces (see the preliminaries (link)).
	An interesting fact is that $\phi$ is positive multiplicative functions if and only if $\phi$ is positive, that is for all positive $f \in V$ we have that
	\begin{equation*}
		\phi(f)\geq 0\quad\forall f\in V.
	\end{equation*}
	The reverse implication is clear and the implication relies on a somewhat technical density argument. The proof can be found in page 149 of \cite{gel2016generalized}. The proof of the following two theorems that characterize positive functions of $V$ can be found in section  $2.2$ of the aforementioned \cite{gel2016generalized}.
	\begin{theorem}\label{positivegives measure}
		A generalized function $\phi\in \mathcal{D}'(\R^d\to\C)$ is positive if and only if there exists a positive (possibly infinite) measure $\mu $ such that
		\begin{equation*}
			\phi(f)=\int_{\R^d} f(x)d\mu(x).
		\end{equation*}
	\end{theorem}
	Things don't work out quite the same when $V=\Ss'(\R^d)$, as the integral may not be well-defined. For his purpose we introduce the following concept,
	\begin{definition}
		A tempered measure is a measure $\mu$ on $\Bb(\R^d)$ such that, for some $k\in \N$
		\begin{equation*}
			\int_{\R^d} \frac{1}{(1+\abs{x}^2)^k}d \mu (x)<\infty .
		\end{equation*}

	\end{definition}

	Using this result one can prove the following, essentially by a density argument
	\begin{theorem}
		A generalized function $\phi\in \mathcal{S}'(\R^d\to\C)$ is positive if and only if there exists a positive tempered measure $\mu $ such that
		\begin{equation*}
			\phi(f)=\int_{\R^d} f(x)d\mu(x).
		\end{equation*}
	\end{theorem}
	Note that by the rapid decrease of $f\in \Ss(\R^d\to\C)$, all these functions can be integrated against tempered measures and the above integral is well defined. Combining all of the above gives the generalization of Bochner's theorem.
	\begin{theorem}[Bochner's generalized theorem]
		An element $\phi\in \Ss'(\R^d\to\C)$ is positive definite if and only if there exists a tempered measure $\mu $ such that $\phi$ is the Fourier transform of $\mu $, that is
		\begin{equation*}
			\phi(f)=\int_{\R^d} \check{f}(\omega) d \mu (\omega),\quad\forall f\in \Ss(\R^d).
		\end{equation*}

	\end{theorem}
	\begin{proof}
		We have already proved in Lemma 1 that $\phi$ is positive definite if and only if it $\check{\phi}$ is multiplicatively positive. Which by the discussion is equivalent to $\check{\phi}$ being positive. As  a result, we obtain by Theorem \ref{positivegives measure} that there exists a tempered measure $\nu $ with
		\begin{equation*}
			\phi(f)=(\Ff\check{\phi})(f)=\frac{1}{(2\pi)^{d}}\check{\phi}(\check{f})=\frac{1}{(2\pi)^{d}}\int_{\R^d} \check{f}(\omega) d \nu (\omega),\quad\forall f\in \Ss(\R^d).
		\end{equation*}
		It now suffices to take $\mu :=(2\pi )^{-d} \nu$.
	\end{proof}
	Note that, if $\phi$ is integration against a continuous positive definite function $r$, then on taking an approximation of unity  $f_n$ and taking limits as $n\to\infty$ we obtain the ordinary Bochner's theorem as a corollary
	\begin{equation*}
		r(x)=\int_{\R^d}e^{i\omega \cdot x} d \mu(\omega) .
	\end{equation*}
	One can also see this formally by setting $f(x)=\delta (x)$. One could hypothesize that the generalized Bochner's theorem would hold for ``untempered measures'' when $\phi\in \mathcal{D}(\R^d\to\C)$. However this is not the case 159 Gelfand
	\begin{theorem}
		An element $\phi\in \mathcal{D}'(\R^d\to \C)$ is positive definite if and only if there exists a tempered measure $\mu $ such that $\phi$ is the Fourier transform of $\mu $, that is
		\begin{equation*}
			\phi(f)=(2\pi^d)\int_{\R^d} \hat{f}(\omega) d \mu (\omega),\quad\forall f\in \mathcal{D}(\R^d\to\C).
		\end{equation*}

	\end{theorem}

	Another nice representation is that positive definite generalized functions are just the derivatives of (ordinary) positive definite functions

	\begin{theorem}
		A generalized function $\phi\in V'$ is positive definite if and only if $\phi=(1-\Delta)^k r$ for some $k\in \N$ and some positive definite function $r\in C(\R^d\to\mathbb{C})$.
	\end{theorem}
	\begin{proof}
		By the previous results we have that if $\phi$ is positive definite then
		\begin{equation*}
			\phi(f)=(2\pi)^d \int_{\R^d}\check{f} d\mu .
		\end{equation*}
		Where $d\nu(\omega):=(1+\abs{\omega}^2)^{-k}d\mu(\omega) $ is a finite measure for some $k$. Let us set
		\begin{equation*}
			r(x)=\overline{\int_{\R^d}e^{i\omega\cdot x} d\nu(\omega)}.
		\end{equation*}
		By Bochner's ordinary theorem $r$ is positive definite (the conjugate of a positive definite functions is positive definite, and by the dominated convergence theorem it is continuous. Furthermore, by the decay of $f$ we may integrate by parts to get
		\begin{equation*}
			\int_{\R^d}\{(1-\Delta )^kf(x)\}e^{i\omega x}=\int_{\R^d}f(x)(1+\abs{\omega}^2)^ke^{i\omega x}dx.
		\end{equation*}
		Putting this all together we obtain that
		\begin{multline*}
			\phi(f)=(2\pi)^d \int_{\R^d}\check{f}(x) d\mu(\omega) = \int_{\R^d} \check{f}(\omega)\frac{(1+\abs{\omega}^2)^{k}}{(1+\abs{\omega}^2)^{k}}d\mu(\omega)\\
			=   \int_{\mathbb{R^d}}\left((1+\abs{\omega}^2)^k\int_{\R^d}f(x)e^{i\omega x}dx\right)d\nu(\omega)
			\\=\int_{\R^d}(1+\Delta)^kf(x)\qty(\int_{\R^d}e^{i\omega\cdot x} d\nu(\omega)) dx=\br{f,(1+\Delta)^k r}
		\end{multline*}
		Where in the second line we used Fubini and in the last line we used the notation $\phi$ for the duality pairing (see above (link)). As a result we have $\phi(\cdot )=\br{\cdot ,(1-\Delta^2)^k r}$ as desired.
	\end{proof}
	We now give the following definiton.
	\begin{definition}
		A \emph{hermitian form} (or \emph{kernel}) on a topological vector space $E$ is a continuous operator $K:E\times E\to \mathbb{C}$ such that for all $f,g,h\in E$ and all $\lambda\in\mathbb{C}$
		\begin{equation*}
			K(\lambda f+g,h)=\lambda K(f,h)+K(g,h);\quad K(f,g)=\overline{K(g,f)}.
		\end{equation*}
		We say that $K$ is positive definite if $$K(f,f)\geq 0,\quad \forall f\in E.$$ In this case we also say that $K$ is a \emph{kernel} on $E$. Furthermore we say that it is translation invariant if $$K(\tau_s f,\tau_s g)=K(f,g),\quad \forall f,g \in V,\quad\forall s\in\mathbb{R}.$$
	\end{definition}
	\begin{observation}
		Note that given a generalized field $\mathfrak{X}$ on $E$ the correlation naturally defines a kernel as
		\begin{equation*}
			K(f,g):=\E[\mathfrak{X} (f)\overline{\mathfrak{X} (g)}].
		\end{equation*}
		Furthermore, by definition $\mathfrak{X}$ is stationary if and only if $\mathfrak{X}$ is stationary.
	\end{observation}
	It can be shown through much hard work (see Gelfand 169, Lototsky 126) that a Hermitian form $K$ on $V$ is translation invariant if and only if  there  exists $\phi\in V'$ such that
	\begin{equation*}
		K(f,g)=\phi(f*g^*).
	\end{equation*}
	If $K$ is a kernel (positive definite) then as a result $\phi$ must also be positive definite and we obtain the following result.
	\begin{lemma}
		A Hermitian positive definite form is stationary if and only if there exists a tempered measure $\mu $ such that
		\begin{equation*}
			K(f,g)=\int_{\R^d}\check{f}\overline{\check{g}}d \mu\quad\forall f,g\in V.
		\end{equation*}
	\end{lemma}
	\begin{proof}
		The proof is a consequence of the characterization of positive definite generalized functions (Bochner's generalized theorem (link)) and the convolution theorem for the Fourier transform.
	\end{proof}
	Applying this to a generalized field $\mathfrak{X}$ on $V$ we obtain that
	\begin{theorem}

		$\mathfrak{X} $ is stationary if and only if their exists a tempered measure such that
		\begin{equation}\label{spectral measure}
			K(f,g):=\E[\mathfrak{X} (f)\overline{\mathfrak{X} (g)}]=\int_{\R^d}\check{f}\overline{\check{g}}d \mu=\br{\check{f},\check{g}}_{L^2(\R^d\to\C,d\mu )}
		\end{equation}
	\end{theorem}
	We call the measure $\mu $ appearing in \eqref{spectral measure} the \emph{spectral measure of $\mathfrak{X}$} furthermore, if $\mu $ is absolutely continuous with respect to the Lebesgue measure on $\R^d$
	with density $S(\omega)$ then we say that $S(\omega)$ is the \emph{spectral density of $\mathfrak{X}$}. Let's see a simple example, first we rigorously define white noise
	\begin{definition}
		Let $H$ be a Hilbert space, then we say that a generalized field  $\Ww$ is \emph{white noise on $H$} if  $\W(f)$ is Gaussian for all $f \in H$ and
		\begin{equation*}
			\E[\W(f)\overline{\W(g)}]=\br{f,g}_{H}, \quad\forall f,g \in L^2(\R^d).
		\end{equation*}
	\end{definition}
	Note that White noise exists on any Hilbert space $H$. To build it it suffices to take an orthonormal basis  $e_k \in H$, a family of independent Gaussian variables $\xi _k \sim \Nn(0,1)$ and set
	\begin{equation*}
		\W(f):=\sum_{k}\br{f,e_k}_H \xi _k .
	\end{equation*}
	The spectral density of $\Ww$ can be calculated simply from our last definition and shows that
	\begin{example}
		Let $\Ww$ be White noise on $L^2(\R^d\to\C),$ then the spectral density of $\Ww$ is $(2\pi )^{-d}$
	\end{example}
	\begin{proof}
		We have that
		\begin{equation*}
			\E[\Ww(f)\overline{\Ww(g)}]=\br{f,g}_{L^2(\R_d\to\C)}=\frac{1}{(2\pi )^d}\br{\check{f},\check{g}}.
		\end{equation*}
	\end{proof}
	\begin{example}
		Let $\mathfrak{X}$ be a stationary generalized field on $V$ with spectral measure $\mu $, then $D^\alpha \mathfrak{X}$ has spectral density $\abs{\omega}^{2\alpha}d\mu(\omega) $
	\end{example}
	\begin{proof}
		We have that given $f,g \in V$
		\begin{equation*}
			\E[D^\alpha\mathfrak{X}(f)\overline{D^\alpha\mathfrak{X}(g)}]=\E[\mathfrak{X}(f)\overline{D^\alpha\mathfrak{X}(g)}]=\br{{D^\alpha}^*f,{D^\alpha}^*g}_{L^2(\R^d\to\C,d\mu )}
		\end{equation*}

	\end{proof}


	We now show that this definition of spectral measure coincides with the conventional definition of spectral measure when $\mathfrak{X}$ is a regular field. And thus generalizes it.
	\begin{proposition}
		Let  $X \in L^2(\R^d\to\C)$ and define the stationary field over $V$
		\begin{equation*}
			\mathfrak{X}(f):=\int_{\R^d}X(x)f(x)dx, \quad\forall f\in V.
		\end{equation*}
		Then the spectral measure of  $X$ is equal to the spectral measure of  $\mathfrak{X}$.
	\end{proposition}
	\begin{proof}
		We have already seen that $X$ will be stationary  if and only if  $\mathfrak{X}$ is stationary. As a result, by Bochner's theorem for ordinary stationary random fields we have that  $X$ has some
		spectral measure  $\nu $ and that for all $f,g \in V$
		\begin{multline*}
			\E[\mathfrak{X} (f)\overline{\mathfrak{X} (g)}]=\E\qty[\int_{\R^d}X(x)f(x) dx\overline{\int_{\R^d}X(y)g(y) dy}]\\=\int_{\R^d}\int_{\R^d}f(x)g(y)r(y-x) dx dy=
			\int_{\R^d}\int_{\R^d} f(x)g(y)\qty(\int_{\R^d}e^{i\omega(x-y)}d\nu(\omega))dxdy \\=\int_{\R^d}\check{f}(\omega)\overline{\check{g}(\omega)}d \nu(\omega) .
		\end{multline*}
		By definition of the spectral measure $\mu $ of $\mathfrak{X}$ we know that the above equality is also true when we substitute $\nu$ with $\mu$. By density of $V$ in  $L^2(\R^d)$ we conclude that $\mu$ and $\nu$ coincide on every bounded indicator function in $\mathcal{B}(\mathbb{R}^d)$. This shows that necessarily $\mu =\nu$.
	\end{proof}



	By now proceeding just as for ordinary random fields we obtain the analogous of the spectral theorem
	\begin{theorem}[The spectral theorem]\label{spectral theorem}
		If $\{\mathfrak{X}(f)\}_{f\in V}$ is a stationary field with mean zero and spectral measure $\mu $, there exists a unique generalized field $dZ$ over $L^2(\R^d\to\C,dF)$ such that
		\begin{equation}\label{spectral representation}
			\mathfrak{X}(f)=dZ(\check{f}),\quad\forall f\in V.
		\end{equation}
		Furthermore, $dZ$ defines a bijective isometry
		\begin{equation*}
			dZ:L^2(\R^d\to\C,\mu )\to\overline{\text{span}(\{\mathfrak{X} (f)\}_{f\in V}}\subset L^2(\Omega\to\C).
		\end{equation*}
		In particular, for any $f,g\in L^2(\R^d\to\C,dF)$,
		\begin{equation}\label{dZ properties}
			\E[dZ(f)]=0;\quad \E[dZ(f)\overline{dZ(g)}]=\int_{\R^d} f\overline{g}d\mu  .
		\end{equation}
	\end{theorem}
	\begin{proof}
		Given $f\in  V$, we define
		\begin{equation}\label{constr phi}
			\varphi(\mathfrak{X} (f)):=\check{f}.
		\end{equation}
		Where we note that $f$ is in $L^2(\R^d\to\C,\mu)$ as $\mu $ is a tempered measure. We then extend this definition linearly to the span of $\{\mathfrak{X} (f)\}_{f\in V}$ by setting
		\begin{equation*}
			\varphi\qty(\sum_{j=1}^N\lambda_j \mathfrak{X} (f_j)):=\sum_{j=1}^N\lambda_j \hat{f}_j\quad\forall N\in \N,f_j\in V.
		\end{equation*}
		Our next step is to show that $\varphi$ defines an isometry. Let $Y:=\sum_{j=1}^N\lambda_j \mathfrak{X} (f_j)$, then by Bochner's theorem (link) and Observation 1(link).
		\begin{multline*}
			\norm{Y}_{L^2(\Omega\to\C)}^2 =\norm{\sum_{j=1}^N\lambda_j \mathfrak{X} (f_j)}_{L^2(\Omega\to\C)}=\sum_{j,k=1}^N\lambda_j\overline{\lambda_k} \E[\mathfrak{X} (f_j)\overline{\mathfrak{X} (f_k)}]\\
			=\sum_{j,k=1}^N\lambda_j\overline{\lambda_k} \int_{\R^d}\check{f}_j\overline{\check{f}_k} d\mu = \int_{\R^d}\abs{\sum_{j=1}^N\lambda_j \check{f}_j}^2d \mu (w)=\norm{\varphi(Y)}_{L^2(\R^d\to\C,d\mu )}^2.
		\end{multline*}
		By the completeness of $L^2(\R^d\to\C, dF)$ and since $\varphi$ is an isometry, we can extend $\varphi$ to a mapping
		$$\varphi:\overline{\text{Span}(\{\mathfrak{X} (f)\}_{f\in V})}\to L^2(\R^d\to\C,\mu ).$$ Furthermore, since $\Ff^{-1}$ is an automorphism of $\Ss(\R^d\to\mathbb{C})$ and since $V\subset \Ss(\R^d\to\mathbb{C})$ is dense, then $\Ff^{-1}V$ is also dense in $\Ss(\R^d\to\mathbb{C})$. By the density of $\Ss(\R^d\to\mathbb{C})$ in $L^2(\R^d\to\C,d\mu )$, we deduce also that $\Ff^{-1}V$ (which is in the image of $\varphi$) is dense in $L^2(\R^d\to\C,\mu )$. As a result $\varphi$ is surjective (and thus bijective as it is an isometry) and we can now define
		\begin{equation*}
			dZ(f):=\varphi^{-1}(f)\quad\forall f\in L^2(\R^d\to\C,\mu ).
		\end{equation*}
		Property \eqref{spectral representation} follows from the construction of $\varphi$ (see equation \eqref{constr phi}). The first part of \eqref{dZ properties} follows from the fact that $\varphi$ is valued in the closure of the span of $\mathfrak{X} (f)$ (which is of mean zero). The second part of \eqref{dZ properties} is because $dZ$ is an isometry, and thus also conserves the inner product. Finally, the uniqueness of $dZ$ follows from the fact that, by property \eqref{spectral representation}, $dZ$ is determined on a dense subset of $L^2(\R^d\to\C,\mu )$ and the continuity of property \eqref{dZ properties}.
	\end{proof}
	Once more, we have that this new theorem generalizes the ordinary case. That is, if $\mathfrak{X}$ is a regular field then both spectral distributions coincide.
	\begin{proposition}
		Let $\mathfrak{X}(f)=\br{X,f}_{L^2(\mathbb{R}^d)}$ be a stationary random field with spectral process $dZ$ and let  $\tilde{dZ}$ be the spectral distribution of $X$. Then  $dZ=\tilde{dZ}$.
	\end{proposition}
	\begin{proof}
		This is a direct consequence of the continuity of $\tilde{dZ}$ on  $L^2(\R^d,d \mu  )$ as we have that, by the spectral representation theorem for ordinary stochastic fields
		\begin{equation*}
			\mathfrak{X}(f)=\br{X,f}_{L^2(\R^d)}=\br{\tilde{dZ}(e^{i\omega\cdot }),f(\cdot )}_{L^2(\R^d)}=\tilde{dZ}\qty(\br{e^{i\omega\cdot },f(\cdot )}_{L^2(\R^d)})= \tilde{dZ}(\check{f}).
		\end{equation*}
		Which concludes the proof by the uniqueness of $dZ$.
	\end{proof}
	Ok, let's see how this works in practice, suppose that I have an SPDE defined as
	\begin{equation*}
		\Ll\mathfrak{X}=dW.
	\end{equation*}
	Where $\Ll:H\to L^2(\R^d)$ is a continuous invertible operator on some dense subset of $L^2(\R^d)$ and $dW$ is white noise on  $L^2(\R^d)$, that is
	\begin{equation*}
		\E[dW(f)dW(g)]=\br{f,g}_{L^2(\R^d)}.
	\end{equation*}
	Then we have that (by definition of $\Ll X$)   the unique solution to the SPDE is \red{adjoint not self adjoint so you get -1}
	\begin{equation*}
		\mathfrak{X}(f)=\mathcal{L}^{-1}\Ww:=\Ww({\Ll^{-1}}^*f), f\in H.
	\end{equation*}
	If $\Ll$ is a stationary operator (which we define to mean that $\mathfrak{X}$ is stationary), then we have that, by definition o White noise and Plancherel's theorem
	\begin{equation*}
		\E[\mathfrak{X}(f)\mathfrak{X}(g)]=\br{{\Ll^{-1}}^*f,{\Ll^{-1}}^*g}_{L^2(\R^d)}=\frac{1}{(2\pi)^d}\br{\mathcal{F}^{-1}({{\Ll^{-1}}^* f)},\mathcal{F}^{-1}({{\Ll^{-1}}^* g)}}_{L^2(\R^d)}.
	\end{equation*}
	If $\Ll=\sum _{\abs{\alpha}\leq k} \lambda _\alpha D^\alpha $ is a differential operator then $\Ll^*=\sum _{\abs{\alpha}\leq k} (-1)^\abs{\alpha}\lambda _\alpha D^\alpha $ and the action on of $\mathcal{L}^*$ the Fourier transform of a function in $H^k(\R^d)$ is defined as
	\begin{equation*}
		\{\mathcal{F}^{-1}({\Ll^* f)}\}(\omega)= \sum _{\abs{\alpha}\leq k}(-1)^\abs{\alpha}(-1)^\abs{\alpha} \lambda _\alpha (i\omega)^\alpha \check{f}(\omega)=\sum _{\abs{\alpha}\leq k}\lambda _\alpha (i\omega)^\alpha \check{f}(\omega).
	\end{equation*}
	Or more succintly, if we write $P(\omega):=\sum _{\abs{\alpha}\leq k}\lambda _\alpha \omega^\alpha$ then
	\begin{equation*}
		\{\mathcal{F}^{-1}({\Ll^* f)}\}(\omega)=P(i\omega)\check{f}(\omega).
	\end{equation*}
	And as a result the action of ${\Ll^{-1}}^*$ is defined as
	\begin{equation*}
		\{\mathcal{F}^{-1}({{\Ll^{-1}}^* f)}\}(\omega)= \{P(i\omega)\}^{-1}\check{f}(\omega).
	\end{equation*}
	In consequence, we obtain that
	\begin{equation*}
		\E[\mathfrak{X}(f)\mathfrak{X}(g)]=\frac{1}{(2\pi)^d}\br{\mathcal{F}^{-1}({{\Ll^{-1}}^*f}),\mathcal{F}^{-1}({\widehat{{\Ll^{-1}}^*g}})}_{L^2(\R^d)}=\int_{\R^d}\frac{\check{f}(\omega)\overline{\check{g}(\omega)}}{(2\pi)^d\{P(i\omega)\}^{2}} d\omega.
	\end{equation*}
	Which shows that the spectral measure is $(2\pi^d)\{P(i\omega)\}^2$. The idea behind all this is that the spectral density of $d$-dimensional white noise is $(2\pi)^{-d}$. As we can also see this measure will be finite when the polynomial has degree greater than $\frac{d}{2}$
	(and doesn't have any roots, but this is already implied by the invertibility of $\Ll$). As an example we can take $H=H^s(\R^d)$  for some $s\in \R$ and define
	\begin{equation*}
		\Ll=(\kappa^2-\Delta)^{s/2}: H\to L^2(\R^d)
	\end{equation*}
	Then we obtain that the spectral density is
	\begin{equation*}
		S(\omega)=\frac{(2\pi)^{-d}}{\left(\kappa^2+\abs{\omega}^2\right)^s}.
	\end{equation*}
	Note that in the case where $s>d/2$ this function will be integrable and in fact, the field $\mathfrak{X}$ will  belong to $L^2(\Omega\times\mathbb{R}^d)$. \red{Prove this}.
\end{CJK*}



\bibliography{biblio.bib}
\end{document}
