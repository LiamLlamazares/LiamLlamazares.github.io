\documentclass[
    a4paper,
    DIV=14,
    abstract=true,
    numbers=noenddot
]
{scrartcl}

\usepackage{
    amsmath,
    amssymb,
    amsthm,
    array,
    authblk,
    bm,
    dsfont, % for 1 vector or indicator function
    graphicx,
    mathtools,
    nicefrac,
    physics,
    tabularx,
    tcolorbox,
    todonotes,
    tikz,
    xcolor,
    float,
}
\usepackage[shortlabels]{enumitem}

\usepackage[T1]{fontenc}

\usepackage[pdffitwindow=false,
    plainpages=false,
    pdfpagelabels=true,
    pdfpagemode=UseOutlines,
    pdfpagelayout=SinglePage,
    bookmarks=false,
    colorlinks=true,
    hyperfootnotes=false,
    linkcolor=blue,
    urlcolor=blue!30!black,
    citecolor=green!50!black]{hyperref}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}

\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{observation}{Observation}
\newtheorem{assumption}{Assumption}

\newtheorem{exercise}{Exercise}

\newtheorem*{hint}{Hint}

\newenvironment{exerciseandhint}[2]
{\begin{exercise} #1

    \emph{Hint: #2}}
    {\end{exercise}}

\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\td}{\todo[inline,color=green!40]}

\bibliographystyle{elsarticle-num}
\newcommand{\fk}[1]{\mathfrak{#1}}
\newcommand{\wh}[1]{\widehat{#1}}
\newcommand{\tl}[1]{\widetilde{#1}}

\newcommand{\br}[1]{\left\langle#1\right\rangle}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\qp}[1]{\left(#1\right)}\newcommand{\qb}[1]{\left[#1\right]}
\newcommand{\qt}[1]{\left(#1\right)}
\newcommand{\Id}{\bm{I}}\renewcommand{\ker}{\rm{ker}}\newcommand{\supp}[1]{\bm{supp}(#1)}\renewcommand{\tr}[1]{\mathrm{tr}\left(#1\right)}
\renewcommand{\norm}[1]{\left\lVert #1 \right\rVert}\renewcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\U}{}\renewcommand{\star}{*}
\renewcommand{\Im}{\bm{Im}}
\newcommand{\iso}{\xrightarrow{\sim}}
\renewcommand{\d}{\,\mathrm{d}}\newcommand{\dx}{\,\mathrm{d}x}
\newcommand{\dy}{\,\mathrm{d}y}
\newcommand\restr[2]{\left.#1\right|_{#2}}
\newcommand{\rm}[1]{\mathrm{#1}}

\newcommand{\A}{\mathbb{A}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Aa}{\mathcal{A}}
\newcommand{\Bb}{\mathcal{B}}
\newcommand{\Cc}{\mathcal{C}}
\newcommand{\Dd}{\mathcal{D}}
\newcommand{\Ff}{\mathcal{F}}
\newcommand{\Gg}{\mathcal{G}}
\newcommand{\Hh}{\mathcal{H}}
\newcommand{\Kk}{\mathcal{K}}
\newcommand{\Ll}{\mathcal{L}}
\newcommand{\Mm}{\mathcal{M}}
\newcommand{\Nn}{\mathcal{N}}
\newcommand{\Oo}{\mathcal{O}}
\newcommand{\Pp}{\mathcal{P}}
\newcommand{\Qq}{\mathcal{Q}}
\newcommand{\Rr}{\mathcal{R}}
\newcommand{\Ss}{\mathcal{S}}
\newcommand{\Tt}{\mathcal{T}}
\newcommand{\Uu}{\mathcal{U}}
\newcommand{\Vv}{\mathcal{V}}
\newcommand{\Ww}{\mathcal{W}}
\newcommand{\Xx}{\mathcal{X}}
\newcommand{\Yy}{\mathcal{Y}}
\newcommand{\Zz}{\mathcal{Z}}

\begin{document}
\title{Elliptic PDE I}
\author{Liam Llamazares}
\date{5/21/2023}
\maketitle
\section{ Three line summary}
\begin{itemize}
	\item Elliptic partial differential equations (PDE) are PDE with no time variable and whose leading order derivatives satisfy a positivity condition.
	\item Using Lax Milgram's theorem we can prove existence and uniqueness of weak (distributional) solutions if the transport term is zero.
	\item If the transport term is non-zero solutions still exist but they are no longer unique and are determined by the kernel of the homogeneous problem.\end{itemize}
\section{Why should I care?}
Many problems arising in physics such as the Laplace and Poisson equation are elliptic PDE. Furthermore, the tools used to analyze them can be extrapolated to other settings such as
elliptic PDE. The analysis also helps contextualize and provide motivation for theoretical tools such as Hilbert spaces, compact operators and Fredholm operators.
\section{Notation}
Given $\alpha \in \C$ we will write $\overline{\alpha }$ for the conjugate of $\alpha $. Given a subset $S$ of some topological space it is also common to write  $\overline{S}$ for the closure of $S$. Though this is a slight abuse of notation we will do the same as the meaning will always be clear from context.

Given two topological vector spaces $X,Y$ we write  $\Ll(X,Y)$ for the space of continuous linear operators from $X$ to  $Y$.

We will use the Einstein convention that indices when they are repeated are summed over. For example we will write
\begin{align*}
	\nabla \cdot (\vb{A}\nabla)=\sum_{i=1}^n \partial_i a_{ij} \partial _j =\partial_i A_{ij} \partial _j.
\end{align*}
Furthermore, we will fix $U \subset \R^n$ to be an open \textbf{bounded} (this will be necessary to apply the PoincarÃ© inequality) set in $\R^n$ with \textbf{no conditions} on the regularity of $\partial U$. If we need to impose regularity on the boundary we will write $\Omega$ instead of $U$.

We will use Vinogradov notation.

\section{Introduction}
Welcome back to the second post on our series of PDE. In the \href{https://nowheredifferentiable.com/2023-01-29-PDE-1/}{first post} of the series we dealt with the Fourier transform and it's application to defining spaces of weak derivatives and weak solutions to PDE. In this post we will consider an equation of the form
\begin{align}\label{PDE}
	\Ll u =f; \quad \restr{u}{\partial U} =0.
\end{align}
Where $\Ll$ is some differential operator, $f: U \to  \R$  is some known function and $u$ is the solution we want to find. We will need the following condition on $\vb{A}$  to prove \emph{well-posedness} of \eqref{PDE}.
\begin{definition} We say that an equation is \emph{well-posed} if
	\begin{enumerate}
		\item It has a solution.
		\item The solution is unique.
		\item The solution depends continuously on the data.
	\end{enumerate}

\end{definition}

\begin{definition}
	Given $\vb{A}: U \to \R^{d \times d}, \vb{b}: U \to \R^d$ and $c:U \to \R$ we say that the differential operator
	\begin{align}\label{operator}
		\Ll u:= -\nabla \cdot (\vb{A} \nabla u)+ \nabla \cdot (\vb{b} u)+c\end{align}
	is \emph{elliptic} if there exists $\alpha>0$ such that
	\begin{align}\label{elliptic}
		\xi ^T\vb{A}(x) \xi  \geq \alpha \abs{\xi }^2 , \quad\forall \xi \in \R^d , \quad\forall x \in U .
	\end{align}
\end{definition}
There are some points to clear up. Firstly, if this is the first time you've encountered  the ellipticity condition in \eqref{elliptic} then it may seem a bit strange.  Physically speaking, in a typical \href{https://nowheredifferentiable.com/2023-12-23-PDEs-4-Physical_derivation_of_parabolic_and_elliptic_PDE/}{derivation} of our PDE in \eqref{PDE}, $u$ is the density of some substance and $\vb{A}$ corresponds to a diffusion matrix. Due to the ellipticity condition \eqref{elliptic} says that flow occurs from the region of \href{https://nowheredifferentiable.com/2023-12-23-PDEs-4-Physical_derivation_of_parabolic_and_elliptic_PDE/#:~:text=a)-,Diffusion,-%3A%20This%20is%20the}{higher to lower density}. Mathematically speaking \eqref{elliptic} will provide the necessary bound we need to apply \href{https://nowheredifferentiable.com/2023-05-30-PDE-2-Hilbert/#:~:text=degenerate.%20As%20a-,particular,-example%2C%20a%20symmetric}{Lax Milgram's theorem}. We have not yet defined which function space our coefficients live in and what $\Ll$ acts on. It would be natural to assume that we need for $\vb{A},\vb{b}$ to be differentiable. However, the following will suffice.
\begin{assumption}\label{Ass1}
	We assume that  $A_{ij}, b_i, c \in L^\infty (U)$ for all $i,j=1,\ldots,d$. Furthermore, $A$ is symmetric, that is  $A_{ij}=A_{ji}$.
\end{assumption}
To simplify the notation we will write for the bound on $\vb{A},\vb{b},c$
\begin{align*}
	\norm{\vb{A}}_{L^\infty(U)}+\norm{\vb{b}}_{L^\infty(U)}+\norm{c}_{L^\infty(U)}=M
\end{align*}

The first assumption will make it easy to get bounds on $\Ll$ and the second will be necessary to apply Lax Milgram's theorem and the third will prove useful when we look at the spectral theory of $\Ll$. Now, to make sense of \eqref{PDE} we need to define what we mean by a solution. Here the theory of Sobolev Spaces and the Fourier transform prove crucial. We will work with the following space
\begin{definition}[Negative Sobolev space]\label{dual definition 2}
	Given $k \in \N$ we define
	\begin{align*}
		H^{-k}(U ):= H_0^k(U )'
	\end{align*}
\end{definition}
For more details on why this notation is used see the appendix \ref{dual section}.

\begin{exercise}\label{domain L}
	Suppose $A_{ij} \in C^{s+1}(\overline{U} ), b_i, c \in C^{s}(\overline{U} )$   for some $s \in \R$. Then, $\Ll $ defines  a bounded linear operator
	\begin{align*}
		\Ll : W_0^{s+2,p}(U)\to W^{s,p} (U).
	\end{align*}
\end{exercise}
\begin{hint}
	Use the chain rule to write $\Ll u$ in the form
	\begin{align*}
		\Ll u =\sum_{\abs{\alpha} \leq 2 } g_\alpha D^\alpha, \quad g_\alpha \in C ^{s}(U).
	\end{align*}
	Using the chain rule again, to show that, for $k=\left\lfloor s \right\rfloor$ and $\gamma =s-k$
	\begin{align*}
		\sum_{\abs{\alpha} \leq k} \Ll u = \sum_{\abs{\alpha} \leq k+2} h_\alpha D^\alpha u, \quad h_\alpha \in C^{\gamma }(U),
	\end{align*}
	and conclude by the definition of $W^{s,p}(U)$.
\end{hint}
In the particular case $s=1$,  we have that $\Ll $ maps $H_0^1(U)$ to its dual $H^{-1}(U)$. This allows us to define the weak formulation of \eqref{PDE} and study its well-posedness using Lax Milgram's theorem. We will do this in the next section.
\section{Weak solutions and well posedness}
We can make sense of the equation $\Ll u =f$ in a distributional (weak) sense as follows.
By an integration by parts, if $u,v \in  C_0^\infty(U)$ then \begin{align*}
	\int_{U} \Ll u v =\int_{U}\vb{A} \nabla u \cdot \nabla v + \int_{U} \vb{b} \cdot ( \nabla  u) v + \int_{U} cuv=: B(u,v)   .
\end{align*}
It is clear that $B$ is bilinear in an algebraic sense. Furthermore from Cauchy Schwartz and  the fact that $\norm{u}_{H^1(U)}\sim \norm{u}_{L^2(U)}+\norm{\nabla u}_{L^2(U\to \R^d)}$ we have the bound
\begin{align}\label{cont B}
	B(u,v)\lesssim M \norm{u}_{H_0^1(U)}\norm{v}_{H_0^1(U)}.
\end{align}
This allows us as to extend by density $B$ from $C_0^\infty(U)$ to a continuous bilinear operator on  $H^1_0(U)$. In which case, by Exercise \ref{domain L} we can consider $f \in H^{-1}(U)$. This gives the following definition.
\begin{definition}[Weak formulation]
	Given $f \in  H^{-1}(U)$, we say that $u~\in~H_0^1(U)$ solves \eqref{PDE} if
	\begin{align}\label{reform}
		B(u,v)= (v,f) , \quad\forall v \in  H^{1}_0(U).
	\end{align}
\end{definition}
We recall the ``duality notation'' $(v,f):= f(v)$. We have now reformulated our problem to something that looks very similar to the setup of Lax Milgram's theorem. In fact, if we suppose $\vb{b}=0$ and $c \geq 0$ we are done.
\begin{theorem}\label{well posed 1}
	Suppose $\vb{b}=0$  and $c \geq 0$. Then, equation \eqref{PDE} is well posed. That is,
	\begin{align*}
		\Ll : H_0^1(U) \iso  H^{-1}(U),
	\end{align*}
	is a homeomorphism. Furthermore, $\norm{\Ll^{-1}} \lesssim_U \alpha ^{-1}$.
\end{theorem}
\begin{proof}
	The continuity of $B$ was proved in  \eqref{reform}. It remains to see that $B$ is coercive. This follows from the fact that for smooth $u$
	\begin{align}\label{b=0}
		B(u,u) & = \int_{U}\vb{A} \nabla u \cdot \nabla u + \int_{U} cu^2 \geq \alpha \norm{\nabla u}_{L^2(U \to \R^d)} \gtrsim_U \norm{u}_{H^1_0(U)}.
	\end{align}
	Where in first inequality we used the ellipticity assumption on $\vb{A}$ and in the last inequality we used PoincarÃ©'s inequality. The result now follows from Lax Milgram's theorem.
\end{proof}
Furthermore, by \href{https://nowheredifferentiable.com/2023-07-12-PDEs-3-Sobolev_spaces/#:~:text=Theorem%2014%20(-,Rellich,-for%20trace%200}{Rellich's theorem} $\Ll$ is compact and is self adjoint since $\vb{b}$ is  $0$ so there is a countable basis of eigenvalues in  $L^2(U)$. Furthermore they must me smooth by Prop  $2$ and Sobolev embedding.

In the previous result, we somewhat unsatisfyingly had to assume that $ \vb{b}$ was identically zero and had to impose the extra assumption  $c \geq 0$. These extra assumptions can be done away with, but at the cost of modifying our initial problem by a correction term $\gamma $ so we can once more obtain a coercive operator $B_\gamma $
\begin{theorem}[Modified problem]\label{mod}
	There exists some constant $\nu \geq 0$ (depending on the coefficients) such that for all $\gamma \geq \nu$  the operator $\Ll_\gamma := \Ll + \gamma \vb{I}$ defines a homeomorphism
	\begin{align*}
		\Ll_\gamma : H_0^1(U) \iso  H^{-1}(U).
	\end{align*}
\end{theorem}
That is, the problem $\Ll u +\gamma u =f$ is well posed for all $\gamma \geq \nu$.
\begin{proof}
	Once more, the proof will go through the Lax-Milgram theorem, where now we work with the bilinear operator $B_\gamma  $ associated to $\Ll_\gamma  $
	\begin{align*}
		B_\gamma  (u,v):= B(u,v) + \gamma  (u,v).
	\end{align*}
	The calculation proceeds in a similar fashion to  \eqref{b=0}, where now an additional application of Cauchy's inequality $ab\leq a^2/2+b^2/2$ $\nabla u v = (\epsilon^{\frac{1}{2}} \nabla u)(\epsilon^{-\frac{1}{2}}v)$  shows that
	\begin{align*}
		B(u,u) & = \int_{U}(\vb{A} \nabla u) \cdot \nabla u + \int_{U} \vb{b}\cdot  (\nabla u) u +  \int_{U} cu^2 \geq \alpha \norm{\nabla u}_{L^2(U \to \R^d)}              \\
		       & - \frac{1}{2}\norm{\vb{b}}_{L^\infty(U)} \qt{\epsilon \norm{\nabla u}_{L^2(U)}+ \epsilon ^{-1}\norm{u}_{L^2(U)}}- \norm{c}_{L^\infty(U)}\norm{u}_{L^2(U)} .
	\end{align*}
	Taking $\epsilon $ small enough (smaller than $ \alpha \norm{\vb{b}}_{L^\infty(U)}^{-1}$ to be precise) and gathering up terms gives
	\begin{align}\label{b not 0}
		B(u,u) \geq \frac{\alpha}{2} \norm{\nabla u}_{L^2(U \to \R^d)} -\nu \norm{u}_{L^2(U)}.
	\end{align}
	Where we defined $\nu = \norm{\vb{b}}_{L^\infty(U)} \epsilon ^{-1}+\norm{c}_{L^\infty(U)}$.The theorem now follows from the just proved \eqref{b not 0} and PoincarÃ©'s inequality as for all $\gamma \geq \nu$
	\begin{align*}
		B_\gamma (u,u)=B(u,u)+ \gamma \norm{u}_{L^2(U)} \geq\frac{\alpha}{2} \norm{\nabla u}_{L^2(U \to \R^d)}\gtrsim _U \norm{u}_{H_0^1(U)} .
	\end{align*}
\end{proof}
We now consider $\Ll u =\lambda u+f$, which is a small generalization of our original problem \eqref{PDE}. We have that,
\begin{align*}
	\Ll u = \lambda u + f \iff  \Ll_\gamma u =(\gamma+\lambda)u +f.
\end{align*}
If we introduce the notation $\mu:=(\gamma+\lambda)$ and rename $v=\mu u +f$ we obtain that the above is equivalent to
\begin{align*}
	(\bm{I}- \mu \Ll_\gamma ^{-1}  )v =f.
\end{align*}
By Rellich-Kondrachov, we know that the inclusion $ i:H^1(U) \hookrightarrow L^2(U)$ is compact. As a result, by Theorem \ref{well posed 1}, we deduce that $\Ll_\gamma^{-1}: L^2(U) \to L^2(U)$, which we are now viewing as an operator on $L^2(U)$, is compact. More precisely $K:= i \circ \restr{\Ll_\gamma ^{-1}}{L^2(U)} $  is compact and the previous reasoning show that, given $f \in L^2(U)$, and $u \in H_0^1(U)$
\begin{align}\label{reasoning}
	\Ll u + \lambda u = f\iff Tu:=(\vb{I}-\mu K)u =f.
\end{align}
Which is exactly the form the \href{https://nowheredifferentiable.com/2023-05-30-PDE-2-Hilbert/#:~:text=Theorem%2010%20(-,Fredholm,-alternative).%20Let}{Fredholm alternative} takes. We can now state the following result.
\begin{theorem}\label{well posednesss Fredholm}
	Let $\Ll$ verify Assumption \ref{Ass1}, let $\lambda>0, f \in L^2(U)$ be any and consider the problems
	\begin{align}
		\begin{minipage}{0.3\linewidth}
			\begin{equation}
				\begin{cases}
					\Ll u = \lambda u+f \\
					u \in H_0^1(U)
				\end{cases}\label{original}
			\end{equation}
		\end{minipage}%
		\begin{minipage}{0.3\linewidth}
			\begin{equation}
				\begin{cases}
					\Ll u = \lambda u \\
					u \in H_0^1(U)
				\end{cases}\label{originalh}
			\end{equation}
		\end{minipage}.
	\end{align}
	\begin{enumerate}
		\item Equation \eqref{original} is well posed if and only if \eqref{originalh} has no non-zero solutions  $(\lambda \notin \sigma(\Ll))$.
		\item The spectrum $\sigma (\Ll )$ is discrete. If $\sigma(\Ll )= \{\lambda_n \}_{n=1}^\infty$ is infinite, then $\lambda _n \to +\infty$.
		\item The dimension of the following  spaces is equal
		      \begin{align*}
			      N:= \set{u \in H_0^1(U): \Ll u = \lambda u}, \quad N^*:= \set{f \in L^2(U): \Ll^* f = \lambda f},
		      \end{align*}
		\item Equation, \eqref{original} has a solution if and only if $f \in (N^*)^\perp$ $($equivalently $\br{w,f}=0$ for all $w \in N^* )$.
	\end{enumerate}
\end{theorem}
\begin{proof}
	Given $f \in L^2(U)$  Consider the following two problems
	\begin{align}
		\begin{minipage}{0.3\linewidth}
			\begin{equation}
				\begin{cases}
					Tv = f \\
					v \in L^2(U)
				\end{cases}\label{fred}
			\end{equation}
		\end{minipage}%
		\begin{minipage}{0.3\linewidth}
			\begin{equation}
				\begin{cases}
					Tv = 0 \\
					v \in L^2(U)
				\end{cases}\label{fredh}
			\end{equation}
		\end{minipage}.
	\end{align}
	The reasoning in \eqref{reasoning} showed that a solution $u$ to \eqref{original} gives a solution to \eqref{fred} via the transformation $v=\mu u +f$. The converse is not clear, as given $v \in L^2(U)$  the inverse transformation $u = \mu ^{-1}(v-f)$ may not return a function in $H_0^1(U)$. However, if $v$  solves \eqref{fred}, then $u$ verifies
	\begin{align*}
		Tv=v-\mu K v=\mu u +f - \mu K v=f.
	\end{align*}
	Cancelling out the $f$ and dividing by $\mu$ we obtain that
	\begin{align*}
		u =Kv.
	\end{align*}
	By Theorem \ref{well posed 1} we know that $Kv = \Ll _\gamma ^{-1} v \in H_0^1(U)$ for all $v \in L^2(U)$ . As a result, $u$ solves \eqref{original} and   we have that \eqref{fred} has a solution if and only if \eqref{original} has a solution. Taking $f=0$ we also obtain that $u$ solves \eqref{originalh}  if and only  $v$  solves \eqref{fredh}. In conclusion,
	\begin{align*}
		\eqref{original} \text{ is } \rm{w.p} \iff \eqref{fred} \text{ is } \rm{w.p} \iff \ker(T) =0 \iff \ker(\Ll +\lambda )=0,
	\end{align*}
	where the second equivalence is the Fredholm alternative.

	To see the second part, note that \eqref{fredh} has non zero solutions if and only if $\mu ^{-1} \in \sigma (K)$. Since $K$ is compact, $\sigma(K)$ is discrete and if it is infinite then its eigenvalues, which we denote by $\left\{\mu _n^{-1}\right\}_{n=1}^\infty$ go to $0$. The claim follows by the correspondence $\lambda =\mu -\gamma$.

	For the final part, we note that we have already proved that $\ker(T)=N$. Additionally,
	\begin{align*}
		T^* =(\vb{I}-\mu K^*) =\vb{I}-\mu (\Ll^*+ \gamma  )^{-1},
	\end{align*}

	from where
	\begin{align*}
		\quad \ker(T^*)=\ker(\Ll^* -\lambda \vb{I})= N^*.
	\end{align*}
	Applying the Fredholm alternative once more concludes the proof.
\end{proof}

\begin{corollary}
	Equation \eqref{PDE} is well posed unless the homogeneous problem $\Ll u=0$ has a non null solution (that is, $\ker(\Ll )\neq 0$). Furthermore,  $\ker(\Ll) $ and $\ker(\Ll ^*)$ have the same dimension.  And \eqref{PDE} will have a solution if and only if $f$ is orthogonal to the kernel of $\Ll^*$.
\end{corollary}


\begin{exercise}
	In Theorem \ref{well posednesss Fredholm} we used that, for $\gamma $ large enough,  $K= \Ll_{\gamma }^{-1} $ is compact. However, $\Ll_{\gamma }^{-1}$ is invertible with inverse $\Ll _\gamma $. As a result $\vb{I}=\Ll _\gamma \circ \Ll _\gamma ^{-1}$  is compact. How is this possible?
\end{exercise}
\begin{hint}
	In fact, $\Ll_\gamma^{-1} $ is only invertible as an operator from $H^{-1}(U) \to H^1_0(U)$. However, it is not invertible as an operator from $K:L^2(U) \to L^2(U)$. Given $f \in L^2(U)$ it is not generally possible to find an $u \in L^2(U)$ such that $\Ll_\gamma u =f$.
\end{hint}
\begin{exercise}
	Where does the proof of Theorem \ref{well posednesss Fredholm} break down if we replace $U$ with $\R^d$?
\end{exercise}
\begin{hint}
	Can you apply Rellich-Kondrachov to unbounded domains? What is the spectrum of the Laplacian on $\R^d$?
\end{hint}
\section{Higher regularity}
We saw in Theorem \ref{well posednesss Fredholm} that given bounded coefficients $\vb{A},\vb{b},c$and $f \in L^2(U)$ the solution to \eqref{PDE} is in $H_0^1(U)$. However, since we are differentiating twice, we can expect that the solution is in fact in $H^2(U)$. This is indeed if we assume some additional regularity on the coefficients. The idea is to use difference quotients to approximate the derivatives.
\begin{align*}
	D_j^h u := \frac{u(x+ he_j)-u(x)}{h},\quad   e_j=(0,\ldots,\overset{(j)}{1},\ldots,0).
\end{align*}
The following lemma shows that, if we are able to bound these, then we can obtain the desired regularity. We show the proof for unbounded domains.
\begin{lemma}[Difference quotients and regularity]
	Let  $p \in (1, +\infty)$, then the following hold.
	\begin{enumerate}
		\item 	If $u \in L^p(\R^d)$ and for all $h$ sufficiently small $\norm{D_j^h u}_{L^p(\R^d)} \leq C$. Then $u \in W^{1,p}(\R^d)$.
		\item  If $u \in W^{1,p}(\R^d)$. Then, for all $h$ sufficiently small $\norm{D_j^h u}_{L^p(\R^d)} \leq C\norm{\nabla u}_{L^p(\R^d)}.$
	\end{enumerate}
\end{lemma}
\begin{proof}
	The idea is to use the fundamental theorem of calculus and the density of smooth functions in $L^p(\R^d)$  to bound the difference quotients. Since $L^p(\R^d)$ is reflexive, this will give a subsequence that converges weakly to some $v \in L^p(\R^d)$. We will show that $v=\nabla u$ almost everywhere.  Suppose first that $u$ is smooth. Then,

\end{proof}


\begin{theorem}[Higher regularity unbounded domain]
	Suppose that $\vb{A}\in C^1(\R^d)$ and that $\bm{b},  \in L^\infty(\R^d \to \R^d), c \in L^\infty(\R^d)$. Then, if $u$ solves $\Ll u=f$, it holds that $u \in H^2(U)$.
\end{theorem}
\begin{proof}
	The idea is to use difference quotients to approximate the second derivative. We will use the following notation
\end{proof}


\begin{theorem}\label{higher regularity}
	Suppose that $\vb{A}\in C^1(U)$ and that $\vb{A}$ is uniformly elliptic. Then, the solution to \eqref{PDE} is in $H^2_{\mathrm{loc}}(U)$.
\end{theorem}
\begin{proof}

\end{proof}

For bounded domains the proof is similar, however one has to be careful as the difference quotients may not be well defined at the boundary. As a result, it is necessary to work locally and use bump functions. This makes the proofs technically a bit messier, though the idea is the same. The proof of the following results can all be found in \cite{evans2022partial} pages (326-344).




\appendix
\section{The dual of a Sobolev space}\label{dual section}
In this section we discuss a bit more on why the notation $H^{-s}(U)=H_0^s(U)'$ in definition \ref{dual definition 2}.
\subsection{The dual of $H^s(\R^d)$}
For some motivation we start by considering the case $U=\R^d$. In this case, since the closure of
$C_c^\infty(\R^d)$ in $H^s(\R^d)$ (which by definition is $H_0^s(\R^d)$) is itself $H^s(\R^d)$, we have that $H_0^s(\R^d)=H^s(\R^d)$.
\begin{exercise}[Dual of Sobolev spaces]\label{dual exercise}
	Prove the identification $H^{-s}(\R^d)=H^s(\R^d)'$.
\end{exercise}
\begin{hint}

	Consider the mapping  $H_0^{-s}(\R^d) \to H^s_0(\R^d)'$ given by $f \mapsto \ell_f$ where
	\begin{align*}
		\ell_f(u):= \int_{\R^d}\wh{u} \wh{f} .
	\end{align*}
	Show that this mapping is well defined and continuous. Then, use the Riesz representation theorem to show that it is surjective with inverse given by the mapping
	\begin{align*}
		H^s(\R^d)'                & \longrightarrow H^{-s}(\R^d)                                 \\
		\ell = \br{\cdot, g_\ell} & \longmapsto \mathcal{F}^{-1}(\br{\xi}^{2s}\wh{g_\ell}(\xi ))
		.\end{align*}


	and show that it is an isomorphism.
\end{hint}
\begin{exercise}
	We also know that, since $H^s(\R^d)$ is a Hilbert space, so by the Riesz representation theorem we have the identification $H^s(\R^d) = H^{s}_0(\R^d)'$. So by the previous exercise $H^{-s}(\R^d)= H^s(\R^d)$ How is this possible?
\end{exercise}
\begin{hint}
	In fact it does \textbf{not} hold that $H^{-s}(\R^d)= H^s(\R^d)$. The problem occurs when considering too many identifications at once. By following the mappings we obtain a bijective isomorphism
	\begin{align*}
		H^{s}(\R^d) \to & H^s(\R^d)' \to H^{-s}(\R^d)                                                              \\
		u \longmapsto   & \br{\cdot, u}_{H^s(\R^d)} \mapsto \mathcal{F}^{-1}\left(\br{\xi}^{2s}\wh{u}(\xi )\right)
	\end{align*}
	Though this is an isomorphism it is hardly the identity mapping.
\end{hint}
For another example where confusion with these kind of identifications can arise see Remark 3 on page  136 of \cite{brezis2011functional}.

\subsection{The dual of $H^k_0(\Omega)$}
Here things get a little bit more complicated, mainly because we have not yet defined what is meant by
$H^s(\Omega)$ when $s$ is not a positive integer. So a priori $H^{-k}(\Omega)$ makes no sense. However, one can use complex interpolation to define such spaces. This done, one can show that if we embed $\Omega$ in a smooth manifold (without boundary) $M$, then $H_0^k(M)'=H^{-k}(M)$ and we can define extension and restriction operators
\begin{align*}
	E:H^s(\Omega ) \to H^s(M), \quad \rho: H^s(M) \to H^s(\Omega ),
\end{align*}
which verify $\rho \circ E = \Id_{H^s(\Omega )}$. As a result, restriction is surjective and we can factor $H^s(\Omega )$ as
\begin{align}\label{ismorphism}
	H^s(\Omega )\simeq H^s(M)\slash H^s_K(M ), \quad K=\overline{M\setminus \Omega }.
\end{align}
Where given a closed set $B\subset M$ we define
\begin{align*}
	H^s_B(M):= \set{u \in H^s(M): \supp{u} \subset B}.
\end{align*}
Now, given a Banach space $X$ and a closed subspace $Y \hookrightarrow X$ it holds that elements of $X'$ can be restricted to $Y'$. The kernel of this restriction is $Y^\circ$, and as a result we obtain the \href{https://math.la.asu.edu/~quigg/teach/courses/578/2008/notes/adjoints.pdf}{factorization}
\begin{align}\label{dual isomormphism}
	Y' \simeq X'\slash Y^\circ, \quad Y^\circ:= \set{\ell \in X': Y \subset \rm{ker}(\ell)}.
\end{align}
Applying this to $Y= H^k_0(\Omega )\hookrightarrow H^k(M) =X$ we obtain
\begin{align*}
	H^{k}_0(\Omega )' \simeq H^{k}(M)'\slash H^{k}_K(M)'\simeq H^{-k}(M)\slash H^{-k}_K(M )\simeq H^{-k}(\Omega ).
\end{align*}
Which justifies the notation in Definition \ref{dual definition}. The reason why we can only consider
integer $k$ is that, for general $s \in \R$, and somewhat surprisingly given the integer case, it does not hold that $H^s_0(\Omega )$ are the distributions with support in $\bar{\Omega}$. That is, in general
\begin{align*}
	H^s_0(\Omega )\neq H^{s}_{\overline{\Omega } }(M).
\end{align*}
Though, by continuity of the trace, given  $ u \in H^s_0(\Omega )$ for $s>1/2$ we have that $\restr{u}{\partial \Omega } =0$.
As a final note, since in this case our domain has a boundary, $H_0^k(\Omega )'$ and $H^k(\Omega )'$ are not equal. Rather,
\begin{align*}
	H^s(\Omega )'\simeq H_{\overline{\Omega } }^{-s}(M), \quad H^{-k}(\Omega ) \simeq H^{-k}(\Omega )\slash H_{\partial \Omega }^{-k}(\Omega ).
\end{align*}
Where the second isomorphism can be seen by taking $X=H^k(\Omega )$ and $Y=H^k_{0 }(\Omega )$ in \eqref{dual isomormphism}. See \cite{taylor2013partial} Section 4 for more details.
\section{Fractional Sobolev spaces and  some generalizations}
In this section we discuss the following:
\begin{enumerate}
	\item There are two ways to define fractional Sobolev spaces. One, denoted by $W^{s,p}(U)$,  is defined by using the analogous to the definition of H\"older spaces. The second, denoted by $H^{s,p}(U)$, is defined by using the Fourier transform. When $U$ is a Lipschitz domain, these two definitions are equivalent.
	\item The dual of $H^{s,p}(\Omega )$ is $H^{-s,p'}(\Omega )$. This is a consequence of the Riesz representation theorem.
\end{enumerate}
\subsection{Fractional Sobolev spaces: two definitions}
\subsubsection{Soboelv-Slodeckij spaces}
\begin{definition}[Sobolev-Slodeckij spaces]\label{soledkij def}
	Let $\gamma  \in (0,1), p \in [1,\infty)$ and $\Omega  \subset \R^n$ be an arbitrary open set we define
	\begin{align*}
		W^{\gamma  ,p}(U):= \set{u \in L^p(U): | u |_{\gamma,p}<\infty},
	\end{align*}
	where
	\begin{align}\label{fractional seminorm}
		| u |_{\gamma  ,p}:= \left(\int_{U}\int_{U}\frac{\abs{u(x+y)-u(x)}^p}{\abs{y}^{n+\gamma p}}\d x \d y\right)^{\frac{1}{p}},
	\end{align}
	and we give it the norm
	\begin{align*}
		\norm{u}_{W^{\gamma,p}(U)}:= \left(\norm{u}_{L^p(U)}^p+| u |_{\gamma ,p}^p\right)^{\frac{1}{p}}.
	\end{align*}
	Now, given $k \in \N$ and $s:=k+\gamma $, we define
	\begin{align*}
		W^{s ,p}(U):= \set{u \in W^{k ,p}(U): \nabla^k  u \in W^{\gamma ,p}(U \to \R^{d^k})}.
	\end{align*}
	And give it the norm
	\begin{align}\label{norm def}
		\norm{u}_{W^{s,p}(U)}:= \left(\norm{u}_{W^{k,p}(U)}^p+ \sum_{\abs{\alpha}=k }\norm{D^\alpha u}_{W^{\gamma ,p}(U)}^p\right)^\frac{1}{p}
	\end{align}
\end{definition}

The above definition mimics that of the H\"older spaces, with the addition that we now require integrability. The factor $\abs{x-y}^{n+\gamma p}$ is chosen so that the norm is scale invariant. That is, if we replace $U$ by $\alpha U$, it holds that $|u|_{s,p}$ by $|u(\alpha \cdot )|_{s,p}$.
\begin{exercise}
	Show that $W^{s,p}(U)$ is a Banach space.
\end{exercise}
\begin{hint}
	To show that $| \cdot |_{s,p}$ is a norm apply Minkowski's inequality to $u$ and to $f_u(x,y):=(u(x)-u(y))/(x-y)^{n/p+s}$. Given a Cauchy sequence show that, since $L^p(U)$ is complete, $u_n \to u$ in $L^p(U)$ and that $f_{u_n} \to f_u$ in $L^p(U\times U)$ to conclude that $u_n \to u$ in $W^{s,p}(U)$.
\end{hint}
Though the Sobolev-Slodeckij spaces can be defined for any open set $U$, they are most useful when $U=\R^d$ or $U$  is bounded open and Lipschitz (that is $U$ is of class $C^{0,1}$). This is because of the following result.
\begin{proposition}[Inclusion ordered by regularity]
	Let  $\Omega \subset \R^d$ be bounded open and Lipschitz. Then, for $p \in [1,\infty)$ and $0<s<s'$ it holds that
	\begin{align*}
		W^{s',p}(\Omega )\hookrightarrow W^{s,p}(\Omega ), \quad W^{s',p}(\R^d)\hookrightarrow W^{s,p}(\R^d).
	\end{align*}
\end{proposition}
The proof can be found in \cite{di2012hitchhiker's} page 10. The regularity of the domain is necessary to be able to extend functions in $W^{1,p}(\Omega )$ to $W^{1,p}(\R^d)$. The result is not true otherwise and an example is given in this same reference.
\subsubsection{Bessel potential spaces}
We now give a second definition of fractional Sobolev spaces through the Fourier transform.
\begin{definition}[Bessel potential spaces on $\R^d$ ]\label{bessel potential def}
	Let $s>0$ and $p \in [1,\infty)$. Define for $u \in \Ss'(\R^d)$
	\begin{align*}
		\Lambda^s u := \Ff^{-1}\left(\br{\xi}^s \wh{u}(\xi)\right).
	\end{align*}

	Then, we define the \emph{Bessel potential space}
	\begin{align*}
		H^{s,p}(\R^d):=\left\{u \in \mathcal{S}^{\prime}(\mathbb{R}^d): \Lambda ^s u \in L^p(\mathbb{R}^d)\right\},
	\end{align*}
	and give it the norm
	\begin{align*}
		\norm{u}_{H^{s,p}(\R^d)}:= \norm{\Lambda^s u}_{L^p(\R^d)}.
	\end{align*}
\end{definition}
In the definition above, is motivated by the case $p=2$. As we saw when we studied Sobolev spaces through the \href{https://nowheredifferentiable.com/2023-01-29-PDE-1-Fourier/#:~:text=Sobolev%20spaces-,Sobolev%20spaces,-form%20a%20particular}{Fourier transform}, $u \in H^k(\R^d)$ if and only if $\Lambda^k u \in L^2(\R^d)$. That is, $H^{k,2}(\R^d)=H^{k}(\R^d)$.  The natural generalization of this fact gives Definition \ref{bessel potential def}. We now extend this to general domains
\begin{definition}[Bessel potential spaces on $U$]
	Let $U \subset \R^d$ be an arbitrary open set. We define,
	\begin{align*}
		H^{s,p}(U):=\left\{u \in \mathcal{D}^{\prime}(U): \text{ there exists } v \in H^{s,p}(\R^d) \text{ such that } \restr{v}{U}=u\right\}.
	\end{align*}
	And give it the norm
	\begin{align*}
		\norm{u}_{H^{s,p}(U)}:= \inf \set{\norm{v}_{H^{s,p}(\R^d)}: \restr{v}{U}=u}.
	\end{align*}
\end{definition}
\subsection{Relationship between the two definitions}
Both the Sobolev-Slobodeckij and Bessel potential spaces can be viewed as a way to fill the gaps between integer valued Sobolev spaces. Both methods differ in the way they do so. The first is defined by the real interpolation method and the second by the complex interpolation method . However, for Lipschitz domains there is no difference between the two definitions
\begin{proposition}[Interpolation and equivalence]\label{equivalence fractional spaces theorem}
	Let $s_0 \neq s_1 \in \R, p \in [1, \infty)$, $0<\theta<1$ and
	\begin{align*}
		s=s_0(1-\theta)+s_1 \theta, \quad p=p_0(1-\theta)+p_1 \theta.
	\end{align*}
	Then, given $\Omega \subset \R^d$ open with uniformly Lipschitz boundary it holds that
	\begin{align*}
		H^{s,p}(\Omega )=\left[H^{s_0,p_0}(\Omega), W^{s_1,p_1}(\Omega)\right]_{\theta}=W^{s,p}(\Omega),
	\end{align*}
	where $[X,Y]_\theta$ denotes the complex interpolation space.
\end{proposition}
The result can be found in \cite{triebel1992theory} page 45 for $\Omega = \R^n$. The general results follows by extension, see \cite{taira2004semigroups} Theorem 6.5 and \cite{leoni2017first} page 424. The equivalence can also be seen for the particular case $p=2$ by a direct calculation.
\begin{observation}
	Different authors use different notation for these spaces. For example, in \cite{triebel1992theory}, the notation $W^{s,p}:= B^{s}_{p,p}=F^s_{p,p}$ is used, where $B^s_{p,q}, F^s_{p,q}$ are respectively Besov and Triebel-Lizorkin spaces. With this notation, one has that, for $p \neq 2$,
	\begin{align*}
		H^{s,p}= F^s_{p,2} \neq B^{s}_{p,p}= W^{s,p}.
	\end{align*}
	In particular, when $s=k$ is an integer, the standard $W^{k,p}$ as defined  \href{https://nowheredifferentiable.com/2023-07-12-PDEs-3-Sobolev_spaces/#:~:text=Hint-,Definition,-10%20(Sobolev%20spaces}{previously} is $H^{k,p}$  and not $B^k_{p,p}$. Whereas, with our notation, always $H^{s,p}=W^{s,p}$.
\end{observation}

\begin{exercise}[Equivalence of fractional spaces]\label{equivalence fractional spaces}
	Show that
	\begin{align*}
		W^{s,2}(\R^d)= H^s(\R^d).
	\end{align*}
\end{exercise}
\begin{hint}
	We want to show that the norms are equivalent. That is, that
	\begin{align*}
		\norm{u}_{W^{s,2}(\R^d)}\sim \norm{u}_{H^s(\R^d)}.
	\end{align*}
	We already know this is the case when $s$ is an integer so it suffices to show that the norms are equivalent for $s= \gamma  \in (0,1)$. That is, that
	\begin{align*}
		|u|_{s,2}^2\sim \int_{\mathbb{R}^d}|\xi|^{2 s}|\mathcal{F} u(\xi)|^2 d \xi
	\end{align*}
	By multiple changes of variable and Plancherel's theorem we have that
	\begin{align*}
		 & |u|_{\gamma ,2}^2  =\int_{\R^d}\int_{\R^d}\frac{\abs{u(x+y)-u(y)}^2}{\abs{x}^{d+2\gamma	}}\d x \d y                                                                                                       = \int_{\R^d}\frac{\norm{\Ff (u(x+\cdot )-u)}^2}{\abs{x}^{d+2\gamma	}}\d x \\
		 & =\int_{\R^d}\int_{\R^d}  \frac{|e^{-2 \pi i x \cdot \xi}-1|^2}{\abs{x}^{d+2\gamma	}}|\wh{u}(\xi)|^2\d x\d\xi =\int_{\R^d}\left(\int_{\R^d}  \frac{1-\cos(2\pi \xi\cdot x)}{\abs{x}^{d+2\gamma	}}\d x\right)|\wh{u}(\xi)|^2\d\xi.
	\end{align*}
	To treat the inner integral we note that it is rotationally invariant and so, by rotating, to the first axis and later changing variable $x \to x / \abs{\xi}$ we get
	\begin{align*}
		\int_{\R^d}  \frac{1-\cos(2\pi \xi\cdot x)}{\abs{x}^{d+2\gamma	}}\d x & =\int_{\R^d}  \frac{1-\cos(2\pi \abs{\xi}x_1 )}{\abs{x}^{d+2\gamma	}}\d x                                          \\
		                                                                      & =\abs{\xi}^{2 \gamma } \int_{\R^d}  \frac{1-\cos(2\pi  x_1) }{\abs{x}^{d+2\gamma	}}\d x\sim \abs{\xi}^{2 \gamma }.
	\end{align*}
	The last integral is finite as, since $d+2\gamma >d$, the tails $\abs{\xi}\to\infty$ are controlled, and since $1-\cos(2\pi x_1)\sim x_1^2\leq \abs{x}^2$ the integrand has order $-d+2(1-\gamma)>-d$ for $\abs{\xi}\sim 0$ . That said, substituting this back into the previous expression gives the desired result.
\end{hint}
The above suggests that integrals of the kind in \eqref{fractional seminorm} can corresponding to differentiating a fractional amount of times. This indeed is the case
\begin{definition}
	Given $\gamma  \in [0,+\infty)$ and $u \in \Ss (\R^d)$ we define the fractional Laplacian as
	\begin{align*}
		(-\Delta )^{\gamma }u(x):= \mathcal{F}^{-1}(\abs{2\pi\xi}^{2\gamma }\wh{u}(\xi )).
	\end{align*}
\end{definition}
\begin{proposition}
	For $\gamma  \in (0,1)$ and $u \in H^s(\R^d)$ it holds that
	\begin{align*}
		(-\Delta )^{\gamma }u(x)=C\int_{\R^d}\frac{u(x)-u(x+y)}{\abs{y}^{d+2\gamma}}\d y,
	\end{align*}
	where $C$ is a constant that depends on $d,\gamma $.
\end{proposition}
\begin{proof}
	The above equality may seem odd at first if we compare with the integral in \eqref{fractional seminorm} where a square appears in the numerator which gives us our $2$  in the $2 \gamma $. However, it is justified by the fact that, by the change of variables $y \to -y$,
	\begin{align*}
		\int_{\R^d}\frac{u(x)-u(x+y)}{\abs{y}^{d+2\gamma}}\d y=\int_{\R^d}\frac{u(x)-u(x-y)}{\abs{y}^{d+2\gamma}}\d y.
	\end{align*}
	So we can get the \emph{second} order difference in the numerator by adding the two integrals.
	\begin{align}\label{second order}
		\int_{\R^d}\frac{u(y)-u(x+y)}{\abs{y}^{d+2\gamma}}\d y=-\frac{1}{2}\int_{\R^d}\frac{u(x+y)-2u(x)+u(x-y)}{\abs{y}^{d+2\gamma}}\d y.
	\end{align}
	That said, we must show that
	\begin{align*}
		\abs{\xi}^{2\gamma }\wh{u}(\xi )\sim \Ff \left(\int_{\R^d}\frac{u(x)-u(x+y)}{\abs{y}^{d+2\gamma}}\d y\right)
	\end{align*}
	Using \eqref{second order} and proceeding as in exercise \ref{equivalence fractional spaces} gives
	\begin{align*}
		 & \Ff \left(\int_{\R^d}\frac{u(x)-u(x+y)}{\abs{y}^{d+2\gamma}}\d y\right)= -\frac{1}{2} \int_{\R^d}\left(\int_{\R^d}\frac{e^{-2\pi i y \cdot \xi}-2+e^{2\pi i y \cdot \xi}}{\abs{y}^{d+2\gamma}}\d y\right) \wh{u}(\xi)\d \xi       \\
		 & =\int_{\R^d}\left(\int_{\R^d}\frac{1-\cos(2\pi y \cdot \xi)}{\abs{y}^{d+2\gamma}}\d y\right) \wh{u}(\xi)\d \xi =\int_{\R^d}  \frac{1-\cos(2\pi  y_1) }{\abs{y}^{d+2\gamma	}}\d y\int_{\R^d}\abs{\xi}^{2 \gamma }\wh{u}(\xi)\d \xi \\& \sim \abs{\xi}^{2 \gamma }\wh{u}(\xi)\d \xi.
	\end{align*}
	This completes the proof, and shows that the explicit expression for $C$ is
	\begin{align*}
		C=\frac{1}{(2\pi)^{2 \gamma }}\int_{\R^d}  \frac{1-\cos(2\pi  y_1) }{\abs{y}^{d+2\gamma	}}\d y.
	\end{align*}
\end{proof}
\subsection{Dual space and the connection with negative $s$}

We now have a description of fractional Sobolev spaces for all $s>0$ and have seen its connection to the fractional Laplacian and the Fourier transform when the integrability index is $p=2$. We now discuss how to extend our study to negative $s$. Thus, covering the whole real line $s \in \R$.

\begin{definition}\label{dual definition}
	Given $s>0, p \in [1,\infty)$ and a bounded Lipschitz domain $\Omega $ we define
	\begin{align*}
		W^{-s,p'}(\Omega ):= W^{s,p}_0(\Omega )',
	\end{align*}
	where $p'$ is the conjugate exponent of $p$.
\end{definition}
This definition seems a bit arbitrary, why should we define $W^{-s,p'}(\Omega )$ as the dual of $W^{s,p}_0(\Omega )$? Why not choose it to be the dual of $W^{s,p}(\Omega )$, and where does the dual appear from in the first place. The following representation theorem provides the answer to these questions.
\begin{theorem}[Riesz representation for $W_0^{s,p}(\Omega )$]\label{riesz representation}
	Let $\Omega \subset \R^d$ be a bounded Lipschitz domain or equal to $\R^d$. Given,  $s>0$ and $p \in [1,\infty)$ write $k=\left\lfloor  s\right\rfloor$ and $\gamma = s- \lfloor s\rfloor$ so $s= k+\gamma $. Then,  every element in $W^{-s,p'}(\Omega )$ is the unique extension of a distribution  of the form
	\begin{align*}
		\sum_{1\leq\abs{\alpha}\leq k}\left( D^\alpha f_\alpha+  D^\alpha (-\Delta )^{\gamma /2} g_\alpha\right)\in \Dd'(\Omega ),\quad \text{where }    f_\alpha, g_\alpha \in L^{p'}(\Omega ).
	\end{align*}

\end{theorem}
\begin{proof}
	Define the mapping
	\begin{align*}
		T: W^{s,p}(\Omega ) & \longrightarrow L^p(\Omega \to \R^n)                                                   \\
		u                   & \longmapsto(D^\alpha u, D^\alpha (-\Delta )^{\gamma /2} u)_{1 \leq\abs{\alpha}\leq k}.
	\end{align*}
	Where the notation just says that we send $u$ to the vector formed by all its derivatives. By our definition of the norm on $W^{s,p}(\Omega )$ \eqref{norm def}, we have that $T$ is an isometry and in particular continuously invertible on its image. Denote the image of $T$ by $X:=\Im(T)$. Given $\ell \in W^{-s,p'}(\Omega )$ we define
	\begin{align*}
		\ell_0: X \to \R, \quad \ell_0(\vb{w}):= \ell(T^{-1}\vb{w}), \quad \forall \vb{w} \in X.
	\end{align*}
	By Hahn Banach's theorem we can extend $\ell_0$ from $X$ to a functional $\ell_1 \in  L^p(\Omega \to \R^n)'$ and by the Riesz representation theorem we have that there exists a unique $\vb{h}=(a_\alpha, b_\alpha)_{1\leq \abs{\alpha}\leq k }\in L^{p'}(\Omega \to \R^n)$ such that
	\begin{align*}
		\ell_1(\vb{w})=\int_{\Omega}\vb{w}\cdot \vb{h}, \quad \forall \vb{w} \in L^p(\Omega \to \R^n).
	\end{align*}
	By construction, it holds that, for all $u \in W^{s,p}(\Omega )$
	\begin{align*}
		\ell(u)=\ell_0(Tu)=\int_{\Omega}Tu\cdot \vb{h}=\sum_{1\leq\abs{\alpha}\leq k}\int_{\Omega}a_\alpha D^\alpha u  +b_\alpha D^\alpha (-\Delta )^{\gamma /2}u.
	\end{align*}
	In particular, this holds for all $u \in \Dd(\Omega )$ and if we set $f_\alpha:=(-1)^\alpha a_\alpha$ and $g_\alpha:=(-1)^\alpha b_\alpha$ we obtain that for all $u \in \Dd(\Omega )$
	\begin{align}\label{representation}
		\ell(u)=\left(u,\sum_{1\leq\abs{\alpha}\leq k} D^\alpha u_\alpha+ \sum_{1\leq\abs{\alpha}\leq k} D^\alpha (-\Delta )^{\gamma /2}v_\alpha\right)=: \omega(u)
	\end{align}
	(we recall the notation $(u,\omega)$ for the duality pairing). By definitions of the norm on $W^{s,p}(\Omega )$ and Cauchy Schwartz, we have that $\omega$ is continuous with respect to the norm on $W^{s,p}(\Omega )$ and so we may extend it uniquely to the closure of $\Dd(\Omega )$ in $W^{s,p}(\Omega )$ which is $W^{s,p}_0(\Omega )$. By \eqref{representation} the extension is necessarily $\omega$. This completes the proof.
\end{proof}
The above theorem shows that $W^{-s,p'}(\Omega )$ can be equivalently formed by differentiating $s$ times functions in $L^{p'}(\Omega )$ and is more natural than the definition in \eqref{dual definition}. The proof also sheds some light as to why we define $W^{-s,p'}(\Omega )$ as the dual of $W^{s,p}_0(\Omega )$ and not as the dual of $W^{s,p}(\Omega )$. The reason is that the elements of $W^{s,p}_0(\Omega )$ are the ones that can be extended to distributions in $\Dd'(\Omega )$ and so are the ones that we can integrate against. Finally, though the extension from $\Dd'(\Omega )$ to $W^{-s,p}(\Omega )$ is unique the functions $f_\alpha, g_\alpha$ will not be, for example if $\abs{\alpha}>0$ it is possible to add a constant to $f_\alpha$ and $g_\alpha$ and still obtain the same result.

\begin{exercise}
	Let $\abs{\beta }=m \in \N$ and $r \in (0,1)$ .  Show that, for any $s>0,$ and $p \in [1,\infty)$
	\begin{align*}
		D^\beta  : W^{s,p}_0(\Omega ) \to W^{s-m,p}(\Omega ), \quad (-\Delta)^{r/2}  : W^{s,p}_0(\Omega ) \to W^{s-r,p}(\Omega ).
	\end{align*}
\end{exercise}
\begin{hint}
	Apply the definition of $W^{s,p}(\Omega )$ \ref{soledkij def} for positive $s$  together with the just proved representation Theorem \ref{riesz representation} for negative $s$.
\end{hint}


\begin{observation}
	Edit extension theorem for uniformly Lipschitz domains and then whenever $C^k$ boundary is invoked $C^{0,1}$ can be used.	The above extension result can also be proved when $\Omega$ is uniformly Lipschitz. In practice, this just means that $\partial\Omega$ and of class $C^{0,1}$ (Lipschitz continuous). See \cite{leoni2017first} pages 423-430 for the details.
\end{observation}









\bibliography{biblio.bib}
\end{document}
