\documentclass[12pt]{article}
\special{papersize=3in,5in}
\usepackage[utf8]{inputenc}
%PACKAGES
\usepackage{CJKutf8}
\usepackage[colorlinks = true,
	linkcolor = blue,
	urlcolor  = black,
	citecolor = blue,
	anchorcolor = blue]{hyperref}
\usepackage[T1]{fontenc}
\makeatletter
\def\ps@pprintTitle{%
	\let\@oddhead\@empty
	\let\@evenhead\@empty
	\let\@oddfoot\@empty
	\let\@evenfoot\@oddfoot
}
\usepackage{amssymb,amsmath,physics,amsthm,xcolor,graphicx}
\usepackage[shortlabels]{enumitem}
\newtheorem{observation}{Observation}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newcommand{\red}[1]{{\color{red}#1}}
\usepackage[colorlinks = true,
	linkcolor = blue,
	urlcolor  = black,
	citecolor = blue,
	anchorcolor = blue]{hyperref}
\usepackage{cleveref}
\bibliographystyle{elsarticle-num}
\newcommand{\A}{\mathbb{A}}\newcommand{\C}{\mathbb{C}}\newcommand{\E}{\mathbb{E}}\newcommand{\F}{\mathbb{F}}\newcommand{\K}{\mathbb{K}}\newcommand{\LL}{\mathbb{L}}\newcommand{\M}{\mathbb{M}}\newcommand{\N}{\mathbb{N}}\newcommand{\PP}{\mathbb{P}}\newcommand{\Q}{\mathbb{Q}}\newcommand{\R}{{\mathbb R}}\newcommand{\T}{{\mathbb T}}\newcommand{\W}{\mathbb{W}}\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Ww}{\mathcal{W}}\newcommand{\Aa}{\mathcal{A}}\newcommand{\Bb}{\mathcal{B}}\newcommand{\Cc}{\mathcal{C}}\newcommand{\Ee}{\mathcal{E}}\newcommand{\Ff}{\mathcal{F}}\newcommand{\Gg}{\mathcal{G}}\newcommand{\Hh}{\mathcal{H}}\newcommand{\Kk}{\mathcal{K}}\newcommand{\Ll}{\mathcal{L}}\newcommand{\Mm}{\mathcal{M}}\newcommand{\Nn}{\mathcal{N}}\newcommand{\Pp}{\mathcal{P}}\newcommand{\Qq}{\mathcal{Q}}\newcommand{\Rr}{{\mathcal R}}\newcommand{\Ss}zzzzz\newcommand{\Tt}{{\mathcal T}}\newcommand{\Zz}{{\mathcal Z}}\newcommand{\Uu}{{\mathcal U}}
\newcommand\restr[2]{{\left.\kern-\nulldelimiterspace #1\vphantom{\big|} \right|_{#2}}}
\newcommand{\br}[1]{\left\langle#1\right\rangle}
\pagestyle{empty}
\setlength{\parindent}{0in}

\begin{document}

\title{Diffusion processes and the Malliavin differential}
\author{Liam Llamazares}
\date{date}
\maketitle
\section{ Three line summary}
\begin{itemize}
	\item Solutions to SDEs of the form $dX=b(X) d t +\sigma (X)dW $ are Malliavin differentiable if $b,\sigma \in C^1(\R)$.
	\item Their Malliavin differential $DX$ can be written as a stochastic integral.
	\item This gives us an SDE linear in $DX$ and can be solved exactly to obtain an explicit expression for  $DX$.
\end{itemize}
\section{Notation}
The same as in the other posts of this series. In particular, we recall the notation $\mathbb{L}^2(I\times\Omega)$ for the set of progressively measurable (link) square integrable stochastic processes. Furthermore, given a stochastic process $X$ such that  $X(t)\in \mathbb{D}^{1,2}$ for each $t\in I$ we write $D_rX(t)$ for the Malliavin differential at  time $r\in I$ of $X(t)$. That is, if
\begin{equation}\label{ce}
	X(t)=\sum_{n=0}^{\infty}  I_n(f_n(\cdot ,t)),\quad f_n(\cdot ,t)\in L^2(S_n).
\end{equation}
is the chaos expansion (link) of $X(t)$ for each  $t$ then we have that
\begin{equation}\label{ced}
	D_rX(t)=\sum_{n=0}^{\infty}  nI_{n-1}(f_n(\cdot ,r,t)) , \quad\forall r,t\in I.
\end{equation}
\section{Introduction}
As anticipated in the summary, we will be working with an SDE of the form
\begin{equation}\label{SDE}
	dX=b(X) d t +\sigma (X)dW .
\end{equation}
It is a classical result of the theory of SDEs that, if $b$ and  $\sigma $ are Lipschitz continuous, then the above equation has a unique solution for each initial data $X_0\in L^2(\Omega)$. That is, there exists a unique continuous adapted process $X\in \mathbb{L}^2(I\times\Omega)$ such that
\begin{equation}\label{X expression}
	X(t)=X(0)+\int_{0}^t b(X(s)) ds+\int_{0}^t \sigma(X(s))  dW(s).
\end{equation}
Our goal will be to obtain an explicit expression for the derivative of $X$. We will do so by directly differentiating in the expression above. As a result, we will need two lemmas that tell us how to differentiate each of the above integrals. The first of these is as follows.
\begin{lemma}
	If $X\in \mathbb{L}^2(I\times\Omega)$ is  Malliavin differentiable for almost all $t$. Then $\int_{0}^t X(s) dW(s)$ is Malliavin differentiable and we have that
	\begin{equation*}
		D_r \int_{0}^t X(s) dW(s)=X(r)+\int_{r}^t X(s) dW(s), \quad\forall r\leq t.
	\end{equation*}
\end{lemma}
\begin{proof}
	Suppose that $D_tX$ is progressively measurable. Then, using the previously studied divergence property (link) and the fact that the Skorohod integral is an extension of the Itô integral (link) gives
	\begin{align*}
		D_r \int_{0}^t X(s) dW(s) & =D_r(\delta X1_{[0,t]}) =X(r)1_{[0,t]}(r)+\delta (D_rX1_{[0,t]}) \\&=X(r)+\int_{0}^t D_r(X(s)) dW(s).
	\end{align*}
	We consider the chaos expansion of $X$. Then, as was seen previously (link), we have that
	\begin{equation*}
		f_n(t_1,\ldots,t_n,t)=0,\quad\forall t\leq\max_{i=1,\ldots,n} t_i .
	\end{equation*}
	So, writing the chaos expansion for $D_rX(s)$  gives
	\begin{equation*}
		D_rX(s)=\sum_{n=0}^{\infty}  nI_{n-1}(f_n(\cdot ,r,s))=0, \quad\forall r>t.
	\end{equation*}
	Substituting in the first equation we derived shows that
	\begin{equation*}
		D_r \int_{0}^t X(s) dW(s)=X(r)+\int_{r}^t X(s) dW(s).
	\end{equation*}
	As a result, we only need to show that $D_r X$ is progressively measurable for all $r<t$.	This follows by some knowledge of how the Malliavin differential works with conditional expectations. We haven't covered this so we refer the reader to \cite{nunno2008malliavin} page 34.
\end{proof}
Our second lemma shows how to differentiate deterministic integrals. In this case, we need a stronger condition than $D_rX(t)$ existing for each fixed $t$.
\begin{lemma}
	Let $X(s)\in \mathbb{D}^{1,2}$ be Malliavin differentiable for each $s\in I$ with
	\begin{equation*}
		\int_{I} \norm{D_rX}_{L^2(I\times\Omega)}^2dr	\end{equation*}
	Then, given $h\in L^2(I)$ it holds that
	\begin{equation*}
		D_t\br{X,h}_{L^2(I)}=\br{D_tX,h}_{L^2(I)}.
	\end{equation*}
\end{lemma}
\begin{proof}
	We will apply Fubini, we have that
	\begin{equation*}
		\br{D_rX,h}_{L^2(I)}=\int_I\sum_{n=0}^{\infty}nI_{n-1}(f_n(\cdot ,r,s))ds=\sum_{n=0}^{\infty}nI_{n-1}\qty(\int_If_n(\cdot ,r,s)h(s)ds).
	\end{equation*}
	Where both Fubini and the commutation of the sum and the integrals are justified by the condition of the lemma, which guarantees that the last sum has finite $L^2(I\times\Omega)$ norm as
	\begin{multline*}
		\int_{I} \norm{\sum_{n=0}^{\infty}nI_{n-1}\qty(\int_If_n(\cdot ,r,s)h(s)ds)}_{L^2(\Omega)}^2d r  \\
		\leq \int_{I}\sum_{n=0}^{\infty}n^2 \left(\int_{\R}\norm{I_{n-1}f_n(\cdot ,r,s)}^2_{L^2(\Omega)}d r\right)ds \norm{h}^2_{L^2(I)}\\
		=\norm{h}^2_{L^2(I)}\int_{I}\sum_{n=0}^{\infty}\norm{D_tX}_{L^2(I\times\Omega)}d t<\infty .
	\end{multline*}
	Where in the first inequality we applied Fubini, Cauchy Schwartz, and the triangle inequality, and in the equality, we used our old calculation of the norm of the Malliavin derivative (link)
	\begin{equation*}
		\norm{D_rX}_{L^2(I\times\Omega)}^2=\sum_{n=0}^{\infty} n!n\|f_n(\cdot ,r )\|_{L^2(I^{n+1})}<\infty.
	\end{equation*}
	The result now follows by noting that, by the linearity of the iterated integrals, it holds that
	the terms
	\begin{equation*}
		\int_If_n(\cdot ,s)h(s)ds	\end{equation*}
	Is the chaos expansion of $\br{X,h}_{L^2(I)}$.
\end{proof}
In particular, by setting $h=1_{[0,t]}$, this shows that
\begin{equation*}
	D_r \int_{0}^t X(s)ds=\int_{0}^t D_rX(s) ds.
\end{equation*}
That is, we can commute the derivative with deterministic integrals. The previous two lemmas together with the chain rule show that, if we take $X_0\in \R$, and the solution to our SDE verifies all necessary conditions, then
\begin{equation*}
	D_rX(t)=\sigma(X_r)+\int_{r}^tb'(X(s))D_rX(s) ds+\int_{r}^t \sigma'(X(s))D_rX(s) dW(s) .
\end{equation*}
\begin{proposition}
	Given our SDE (link) with $\sigma ,b\in C^1_b(\R)$ it holds that there exists a unique solution $X_t$ and for all $r\leq t$ we have
	\begin{multline*}
		D_rX(t)=\sigma(X_r)+\int_{r}^tb'(X(s))D_rX(s) ds+\int_{r}^t \sigma'(X(s))DX(s) dW(s) .
	\end{multline*}
\end{proposition}
\begin{proof}
	The proof is quite technical and we merely sketch it. The full detail in \cite{nunno2008malliavin} page 120.    By the previous discussion, it is only necessary to show that $X$ verifies the conditions of the lemma, i.e. is Malliavin differentiable and its differential verifies that
	\begin{equation*}
		\int_{\R}\norm{D_tX}_{L^2(I\times\Omega)} d t<\infty.
	\end{equation*}
	This is proved by a Picard iteration
	\begin{equation*}
		X_{n+1}=x_0+\int_{0}^t b(X_n(s)) ds+\int_{0}^t\sigma (X_n(s)) dW(s).
	\end{equation*}
	The aim is to prove that $X_n$ are differentiable with
	\begin{equation*}
		\norm{D_rX_n}_{L^2(I\times\Omega)}^2<\infty , \quad\forall r\in I, \quad\forall n\in \N.
	\end{equation*}
	For the case $n=0$ this is clear as we have that
	\begin{equation*}
		D_rX_1(t)=D_r[x_0+b(x_0)t+\sigma (x_0) W(t)]=\sigma(x_0)+1_{[r,t]}.
	\end{equation*}
	For the general case, the condition of the Lemma 1 is a consequence of the hypothesis of induction on $X_n$ and the chain rule.  Verifying the conditions of Lemma 2 (and in fact stronger bounds on the supremum of $X$) can be done using the Burkholder–David–Gundy inequality. Once that is done, one can prove through a discrete version of Gronwall's inequality that $D_rX_n$ are bounded uniformly in  $n$. Since we know by classical theory of SDEs that $X_n\to X\in L^2(I\times\Omega)$ this is sufficient to show that	\begin{equation*}
		\lim_{n \to \infty}D_rX_n=D_rX.
	\end{equation*}
	Completing the proof.
\end{proof}
We now show how to obtain an explicit expression for $D_rX$ by using that the equation verified by  $D_rX$ is linear (in  $D_rX$ as opposed to $X$). Doing so uses a generalized version of Ito's formula for stochastic coefficients.

\begin{theorem}
	Let $b,\sigma \in C^1_b(I)$ and $X$ verify  the SDE
	\begin{equation*}
		X(t)=b(X(t))d t +\sigma(X(t)) dW(t).
	\end{equation*}
	Then $X(t)$ is Malliavin differentiable on $[0,t]$ with
	\begin{equation*}
		D_r X_t=\sigma\left(X_t\right) \exp \left(\int_r^t\left(b\left(X_s\right)-\frac{1}{2}\left(\sigma^{\prime}\right)^2\left(X_s\right)\right) d s+\int_r^t \sigma^{\prime}\left(X_s\right) d W(s)\right).
	\end{equation*}
	\begin{proof}
		Let us fix any $r\leq t$ and set. Then
		\begin{equation*}
			Y_r(s):=D_rX(s);\quad  u(s):=b'(X(s));\quad v(s):=\sigma'(X(s))
		\end{equation*}
		Then we have that, since $b',\sigma '$ are bounded, $u\in \mathbb{L}^1([0,t]\times\Omega),v\in \mathbb{L}^2([0,t]\times\Omega)$ and for each fixed $r\in  \R$ it holds that
		\begin{equation*}
			Y_r(s)=Y_r(r)+\int_{r}^t u(s)Y_r(s) ds+\int_{r}^t v(s)Y_r(s)  dW(s) .
		\end{equation*}
		Where we define $Y_r(0):=\sigma (X_r)$. Symbolically we have the family of linear SDEs starting at time $r$
		\begin{equation*}
			dY_r(s)=u(s)Y_r(s) ds+v(s)Y_r(s)  dW(s);\quad Y_r(r)=\sigma(X(r)).
		\end{equation*}
		Consider
		\begin{equation*}
			Z(t):=\int_r^t\left(u(t)-\frac{1}{2}v^2(s)\right) d s+\int_r^t v(s) d W(s)
		\end{equation*}
		Which solves the differential equation
		\begin{equation*}
			dZ=\left(u-\frac{1}{2}v^2\right)d t+v(s)dW(s) .
		\end{equation*}
		Applying Itô to  $g(z):=e^z$ gives
		\begin{equation*}
			d g(Z)=g'dZ+\frac{1}{2}g''v^2d t= e^Z[(u-\frac{1}{2}v^2+\frac{1}{2}v^2)d t+vdW]\\=
			g(Z)(u d t +vdW).
		\end{equation*}
		Setting $Y_r=Y_r(r)g(Z)$ proves the result by the uniqueness of solutions as both sides verify the same SDE (note that  $Y_r(r)g(Z)$ has the same stochastic differential as $g(Z)$ but now takes initial data  $Y_r(r)$).
	\end{proof}
\end{theorem}
We end this post by noting that  Proposition $1$ (link) has a multidimensional generalization which can also be found in Nualart's book \cite{nualart2018introduction}, on page 119.

\bibliography{biblio.bib}

\end{document}

