---
author:
- Liam Llamazares
bibliography:
- biblio.bib
date: date
title: Diffusion processes and the Malliavin differential
---

#  Three line summary

-   Solutions to SDEs of the form $dX=b(X) d t +\sigma (X)dW$ are
    Malliavin differentiable if $b,\sigma \in C^1({\mathbb R})$.

-   Their Malliavin differential $DX$ can be written as a stochastic
    integral.

-   This gives us an SDE linear in $DX$ and can be solved exactly to
    obtain an explicit expression for $DX$.

# Notation

The same as in the other posts of this series. In particular, we recall
the notation $\mathbb{L}^2(I\times\Omega)$ for the set of progressively
measurable (link) square integrable stochastic processes. Furthermore,
given a stochastic process $X$ such that $X(t)\in \mathbb{D}^{1,2}$ for
each $t\in I$ we write $D_rX(t)$ for the Malliavin differential at time
$r\in I$ of $X(t)$. That is, if $$\label{ce}
    X(t)=\sum_{n=0}^{\infty}  I_n(f_n(\cdot ,t)),\quad f_n(\cdot ,t)\in L^2(S_n).$$
is the chaos expansion (link) of $X(t)$ for each $t$ then we have that
$$\label{ced}
    D_rX(t)=\sum_{n=0}^{\infty}  nI_{n-1}(f_n(\cdot ,r,t)) , \quad\forall r,t\in I.$$

# Introduction

As anticipated in the summary, we will be working with an SDE of the
form $$\label{SDE}
    dX=b(X) d t +\sigma (X)dW .$$ It is a classical result of the theory
of SDEs that, if $b$ and $\sigma$ are Lipschitz continuous, then the
above equation has a unique solution for each initial data
$X_0\in L^2(\Omega)$. That is, there exists a unique continuous adapted
process $X\in \mathbb{L}^2(I\times\Omega)$ such that
$$\label{X expression}
    X(t)=X(0)+\int_{0}^t b(X(s)) ds+\int_{0}^t \sigma(X(s))  dW(s).$$
Our goal will be to obtain an explicit expression for the derivative of
$X$. We will do so by directly differentiating in the expression above.
As a result, we will need two lemmas that tell us how to differentiate
each of the above integrals. The first of these is as follows.

::: lemma
**Lemma 1**. *If $X\in \mathbb{L}^2(I\times\Omega)$ is Malliavin
differentiable for almost all $t$. Then $\int_{0}^t X(s) dW(s)$ is
Malliavin differentiable and we have that
$$D_r \int_{0}^t X(s) dW(s)=X(r)+\int_{r}^t X(s) dW(s), \quad\forall r\leq t.$$*
:::

::: proof
*Proof.* Suppose that $D_tX$ is progressively measurable. Then, using
the previously studied divergence property (link) and the fact that the
Skorohod integral is an extension of the Itô integral (link) gives
$$\begin{aligned}
        D_r \int_{0}^t X(s) dW(s) & =D_r(\delta X1_{[0,t]}) =X(r)1_{[0,t]}(r)+\delta (D_rX1_{[0,t]}) \\&=X(r)+\int_{0}^t D_r(X(s)) dW(s).
    \end{aligned}$$ We consider the chaos expansion of $X$. Then, as was
seen previously (link), we have that
$$f_n(t_1,\ldots,t_n,t)=0,\quad\forall t\leq\max_{i=1,\ldots,n} t_i .$$
So, writing the chaos expansion for $D_rX(s)$ gives
$$D_rX(s)=\sum_{n=0}^{\infty}  nI_{n-1}(f_n(\cdot ,r,s))=0, \quad\forall r>t.$$
Substituting in the first equation we derived shows that
$$D_r \int_{0}^t X(s) dW(s)=X(r)+\int_{r}^t X(s) dW(s).$$ As a result,
we only need to show that $D_r X$ is progressively measurable for all
$r<t$. This follows by some knowledge of how the Malliavin differential
works with conditional expectations. We haven't covered this so we refer
the reader to [@nunno2008malliavin] page 34. ◻
:::

Our second lemma shows how to differentiate deterministic integrals. In
this case, we need a stronger condition than $D_rX(t)$ existing for each
fixed $t$.

::: lemma
**Lemma 2**. *Let $X(s)\in \mathbb{D}^{1,2}$ be Malliavin differentiable
for each $s\in I$ with $$\int_{I} \norm{D_rX}_{L^2(I\times\Omega)}^2dr$$
Then, given $h\in L^2(I)$ it holds that
$$D_t\left\langle X,h\right\rangle_{L^2(I)}=\left\langle D_tX,h\right\rangle_{L^2(I)}.$$*
:::

::: proof
*Proof.* We will apply Fubini, we have that
$$\left\langle D_rX,h\right\rangle_{L^2(I)}=\int_I\sum_{n=0}^{\infty}nI_{n-1}(f_n(\cdot ,r,s))ds=\sum_{n=0}^{\infty}nI_{n-1}\qty(\int_If_n(\cdot ,r,s)h(s)ds).$$
Where both Fubini and the commutation of the sum and the integrals are
justified by the condition of the lemma, which guarantees that the last
sum has finite $L^2(I\times\Omega)$ norm as $$\begin{gathered}
        \int_{I} \norm{\sum_{n=0}^{\infty}nI_{n-1}\qty(\int_If_n(\cdot ,r,s)h(s)ds)}_{L^2(\Omega)}^2d r  \\
        \leq \int_{I}\sum_{n=0}^{\infty}n^2 \left(\int_{{\mathbb R}}\norm{I_{n-1}f_n(\cdot ,r,s)}^2_{L^2(\Omega)}d r\right)ds \norm{h}^2_{L^2(I)}\\
        =\norm{h}^2_{L^2(I)}\int_{I}\sum_{n=0}^{\infty}\norm{D_tX}_{L^2(I\times\Omega)}d t<\infty .
    \end{gathered}$$ Where in the first inequality we applied Fubini,
Cauchy Schwartz, and the triangle inequality, and in the equality, we
used our old calculation of the norm of the Malliavin derivative (link)
$$\norm{D_rX}_{L^2(I\times\Omega)}^2=\sum_{n=0}^{\infty} n!n\|f_n(\cdot ,r )\|_{L^2(I^{n+1})}<\infty.$$
The result now follows by noting that, by the linearity of the iterated
integrals, it holds that the terms $$\int_If_n(\cdot ,s)h(s)ds$$ Is the
chaos expansion of $\left\langle X,h\right\rangle_{L^2(I)}$. ◻
:::

In particular, by setting $h=1_{[0,t]}$, this shows that
$$D_r \int_{0}^t X(s)ds=\int_{0}^t D_rX(s) ds.$$ That is, we can commute
the derivative with deterministic integrals. The previous two lemmas
together with the chain rule show that, if we take $X_0\in {\mathbb R}$,
and the solution to our SDE verifies all necessary conditions, then
$$D_rX(t)=\sigma(X_r)+\int_{r}^tb'(X(s))D_rX(s) ds+\int_{r}^t \sigma'(X(s))D_rX(s) dW(s) .$$

::: proposition
**Proposition 1**. *Given our SDE (link) with
$\sigma ,b\in C^1_b({\mathbb R})$ it holds that there exists a unique
solution $X_t$ and for all $r\leq t$ we have $$\begin{gathered}
        D_rX(t)=\sigma(X_r)+\int_{r}^tb'(X(s))D_rX(s) ds+\int_{r}^t \sigma'(X(s))DX(s) dW(s) .
    \end{gathered}$$*
:::

::: proof
*Proof.* The proof is quite technical and we merely sketch it. The full
detail in [@nunno2008malliavin] page 120. By the previous discussion, it
is only necessary to show that $X$ verifies the conditions of the lemma,
i.e. is Malliavin differentiable and its differential verifies that
$$\int_{{\mathbb R}}\norm{D_tX}_{L^2(I\times\Omega)} d t<\infty.$$ This
is proved by a Picard iteration
$$X_{n+1}=x_0+\int_{0}^t b(X_n(s)) ds+\int_{0}^t\sigma (X_n(s)) dW(s).$$
The aim is to prove that $X_n$ are differentiable with
$$\norm{D_rX_n}_{L^2(I\times\Omega)}^2<\infty , \quad\forall r\in I, \quad\forall n\in \mathbb{N}.$$
For the case $n=0$ this is clear as we have that
$$D_rX_1(t)=D_r[x_0+b(x_0)t+\sigma (x_0) W(t)]=\sigma(x_0)+1_{[r,t]}.$$
For the general case, the condition of the Lemma 1 is a consequence of
the hypothesis of induction on $X_n$ and the chain rule. Verifying the
conditions of Lemma 2 (and in fact stronger bounds on the supremum of
$X$) can be done using the Burkholder--David--Gundy inequality. Once
that is done, one can prove through a discrete version of Gronwall's
inequality that $D_rX_n$ are bounded uniformly in $n$. Since we know by
classical theory of SDEs that $X_n\to X\in L^2(I\times\Omega)$ this is
sufficient to show that $$\lim_{n \to \infty}D_rX_n=D_rX.$$ Completing
the proof. ◻
:::

We now show how to obtain an explicit expression for $D_rX$ by using
that the equation verified by $D_rX$ is linear (in $D_rX$ as opposed to
$X$). Doing so uses a generalized version of Ito's formula for
stochastic coefficients.

::: theorem
**Theorem 1**. *Let $b,\sigma \in C^1_b(I)$ and $X$ verify the SDE
$$X(t)=b(X(t))d t +\sigma(X(t)) dW(t).$$ Then $X(t)$ is Malliavin
differentiable on $[0,t]$ with
$$D_r X_t=\sigma\left(X_t\right) \exp \left(\int_r^t\left(b\left(X_s\right)-\frac{1}{2}\left(\sigma^{\prime}\right)^2\left(X_s\right)\right) d s+\int_r^t \sigma^{\prime}\left(X_s\right) d W(s)\right).$$*

::: proof
**Proof.* Let us fix any $r\leq t$ and set. Then
$$Y_r(s):=D_rX(s);\quad  u(s):=b'(X(s));\quad v(s):=\sigma'(X(s))$$ Then
we have that, since $b',\sigma '$ are bounded,
$u\in \mathbb{L}^1([0,t]\times\Omega),v\in \mathbb{L}^2([0,t]\times\Omega)$
and for each fixed $r\in  {\mathbb R}$ it holds that
$$Y_r(s)=Y_r(r)+\int_{r}^t u(s)Y_r(s) ds+\int_{r}^t v(s)Y_r(s)  dW(s) .$$
Where we define $Y_r(0):=\sigma (X_r)$. Symbolically we have the family
of linear SDEs starting at time $r$
$$dY_r(s)=u(s)Y_r(s) ds+v(s)Y_r(s)  dW(s);\quad Y_r(r)=\sigma(X(r)).$$
Consider
$$Z(t):=\int_r^t\left(u(t)-\frac{1}{2}v^2(s)\right) d s+\int_r^t v(s) d W(s)$$
Which solves the differential equation
$$dZ=\left(u-\frac{1}{2}v^2\right)d t+v(s)dW(s) .$$ Applying Itô to
$g(z):=e^z$ gives
$$d g(Z)=g'dZ+\frac{1}{2}g''v^2d t= e^Z[(u-\frac{1}{2}v^2+\frac{1}{2}v^2)d t+vdW]\\=
            g(Z)(u d t +vdW).$$ Setting $Y_r=Y_r(r)g(Z)$ proves the
result by the uniqueness of solutions as both sides verify the same SDE
(note that $Y_r(r)g(Z)$ has the same stochastic differential as $g(Z)$
but now takes initial data $Y_r(r)$). ◻*
:::
:::

We end this post by noting that Proposition $1$ (link) has a
multidimensional generalization which can also be found in Nualart's
book [@nualart2018introduction], on page 119.
