---
layout: post
title: The Ornstein-Uhlenbeck Semigroup
subtitle: Part 7 of the series on Malliavin calculus
thumbnail-img: /assets/img/Malliavin.jpg
share-img: /assets/img/Malliavin.jpg
tags: [Malliavin calculus, Semigroups]
authorpost: L.Llamazares
---
#  Three line summary

-   There is a natural extension of the Laplacian to the Wiener space.

-   The generator of the Laplacian is the Ornstein-Uhlenbeck semigroup.

-   The Ornstein-Uhlenbeck semigroup in finite dimensions is the
    generator of the Ornstein-Uhlenbeck process, from which it derives
    its name.
    # The Laplacian of a random variable

    First, we give some finite-dimensional motivation. Suppose that
    $f\in C\U c^\infty({\mathbb R}^d\to{\mathbb R}^d)$ and
    $g\in C\U c^\infty({\mathbb R}^d)$. Then an integration by parts shows
    that the adjoint of the gradient in $L^2({\mathbb R}^d)$ is minus the
    divergence. That is,


    <div>
     $$\int\U \mathbb{R}^df(x) \cdot \nabla g(x) dx=-\int\U \mathbb{R}^d\nabla\cdot  f(x) \nabla g(x) dx.$$
    </div>


    Then, we define the Laplacian as minus the adjoint of the gradient
    $\nabla$ composed with the gradient


    <div>
     $$\Delta := -\nabla^\circ \nabla .$$
    </div>

      Which gives the familiar


    <div>
     $$\Delta\U \mathbb{R}^d =\nabla\cdot \nabla=\partial\U 1^2+\ldots\partial \U d^2.$$
    </div>


Of course, this is all well and good when the domain of $f,g$ is a
finite-dimensional space. Otherwise, there is no Lebesgue measure. We
now move to what is our base case in our series of blog posts and
consider a probability space $(\Omega,\mathbb{P},\mathcal{F}\U t)$ where
$\mathcal{F}\U t$ is generated by a Wiener process $W\U t$. Then, as we have
seen [previously](https://nowheredifferentiable.com/2022-07-02-Malliavin-Calculus-4/#:~:text=Malliavin%20derivative%20are-,adjoint,-in%20the%20following) the Skorohod integral $\delta$ is the adjoint of
the Malliavin derivative $D$ so we would like to define


<div>
 $$\Delta  := -\delta \circ D.$$
</div>

  On what kind of random variables can we
define this? Well let us take $X=\sum\U {n=0}^{\infty}  I\U n(f\U n)$ with a
rapidly decaying chaos expansion, then


<div>
 $$\Delta X=-\delta (DX)=-\delta \left(\sum\U {n=1}^\infty nI\U {n-1}(f\U n(\cdot ,t))\right)=-\sum\U {n=1}^\infty nI\U {n}(f\U n).$$
</div>


All we require for this expression to make sense is that- the right-hand
side is in $L^2(\Omega)$. That is, by Ito's $n$-th [isometry](https://nowheredifferentiable.com/2022-05-26-Malliavin-Calculus-1/#:~:text=As%20a%20result-,we,-also%20get%20by), that


<div>
 $$\sum\U {n=0}^\infty n^2 \norm{f\U n}\U {L^2(I\U n)}< \infty.$$
</div>

  Is this a space
we've dealt with before? Well if we recall our [old spaces](https://nowheredifferentiable.com/2022-07-02-Malliavin-Calculus-3/#:~:text=In%20the%20same%20fashion%20as%20before)
$\mathbb{D}^{k,p}$. Then we have that

<div>
 $$\begin{gathered}
        \int\U {I^2}\norm{D\U {t,s}X}\U {L^2(\Omega)}^2 ds d t=\int\U {I^2}\norm{\sum\U {n=2}^\infty n(n-1)I\U {n-2}(f\U n(\cdot ,s,t))}\U {L^2(\Omega)}^2\\=\int\U {I^2}\sum\U {n=2}^\infty n^2(n-1)^2(n-2)!\norm{f\U n(\cdot ,s,t)}\U {L^2(I\U {n-2})}^2=\sum\U {n=2}^\infty n(n-1)n!\norm{f\U n(\cdot ,s,t)}\U {L^2(I\U n)}^2.
    \end{gathered}$$
</div>

  Where analogous calculations go through if we have
more derivatives to get the terms $n(n-1)\cdots (n-(k-1))$. This shows
that


<div>
 $$\mathbb{D}^{k,p}:=\left\{X\in L^2(\Omega):\quad \norm{X}\U {\mathbb{D}^{k,2}}=\sum\U {n=0}^\infty n^kn! \norm{f\U n}\U {L^p(I\U n)}< \infty\right\} .$$
</div>


Thus, the domain of $\Delta$ is exactly $\mathbb{D}^{2,2}$. This is
quite pleasing as, as we have observed earlier, the spaces
$\mathbb{D}^{k,p}$ mimic the Sobolev spaces $W^{k,p}$, when $p=2$ this
resemblance is quite strong as we have that the norm on $H^k:=W^{k,2}$
is


<div>
 $$\norm{f}\U {H^k{\mathbb R}^d)}=\int\U \mathbb{R}^d\left\langle\xi \right\rangle^k \hat{f}(\xi )^2d\xi .$$
</div>


Which is formally equal to the one just derived for $\mathbb{D}^{k,2}.$
It is very interesting to observe that, directly from the definition, we
obtain a basis of eigenvalues of $\Delta$. Let us define


<div>
 $$H\U n:=\{X\in L^2(\Omega): X=I\U n(f\U n),\quad \text{for some } f\U n \in L^2\U S(I^n)  \} .$$
</div>


That is, $H\U n$ are the random variables that only have the $n$-th term
in their chaos expansion to be non-zero. Then by the chaos expansion
theorem, we know that


<div>
 $$L^2(\Omega)=\overline{\oplus\U {n=0}^\infty H\U n}.$$
</div>

  And by construction
of the Laplacian, $\Delta e\U n=n e\U n$ for every $e\U n \in H\U n$. In fact,
by the uniqueness of the chaos expansion, the elements of $H\U n$ for some
$n \in \mathbb{N}$ are the unique eigenvectors of $\Delta .$

# The Ornstein-Uhlenbeck semigroup

As it turns out, $\Delta$ defines a semigroup


**Definition 1**. The Ornstein-Uhlenbeck semigroup is the family of
operators $\Phi(t):L^2(\Omega)\to L^2(\Omega)$


<div>
 $$\Phi(t)X:=\sum\U {n=0}^{\infty}  e^{-nt}I\U n(f\U n),  \quad\forall t\in I.$$
</div>




The term $e^{-nt}$ is quite reminiscent of the semigroup for the heat
equation


<div>
 $$e^{t\Delta }u\U 0:=\int\U \mathbb{R}^de^{-4 \pi^2 \xi^2t}\widehat{u\U 0}(\xi ) d\xi,$$
</div>


and will cause an analogous smoothing effect by making the terms in the
chaos expansion to decrease faster. To see that $\Phi$ defines a
semigroup first note that, by the linearity of the iterated integrals,


<div>
 $$\Phi(t)X:=\sum\U {n=0}^{\infty}  I\U n(e^{-nt}f\U n).$$
</div>

  So as a result


<div>
 $$\Phi(t+s)X=\sum\U {n=0}^{\infty}  e^{-nt}I\U n(e^{-ns}f\U n)=\sum\U {n=0}^{\infty}  \Phi(t)\Phi(s)X.$$
</div>


Which shows that $\Phi(t+s)=\Phi(t)\circ \Phi(s)$. Finally, note that


<div>
 $$\frac{\Phi(t)X-X}{t}=\sum\U {n=0}^{\infty} \left(\frac{e^{-nt}-1}{nt} \right)nI\U n(f\U n)\to -\sum\U {n=0}^{\infty}  nI\U n(f\U n)=\Delta X \in L^2(\Omega)  .$$
</div>


Where the commutation under the integral sign (with the counting
measure) is justified as $(e^{-nt}-1)/(nt)$ is uniformly bounded in $n$.
There's an explicit formula for $\Phi(t)$.
**Proposition 1** (Mehler's formula). Let
$(\Omega,\mathcal{F}\U t,\gamma  )$ be the Wiener space, then


<div>
 $$\Phi(t)X(\omega)=\int\U {\Omega}X\left(e^{-t}\omega+\sqrt{1-e^{-2t}}\eta\right) \gamma  (\eta)\in L^2(\Omega).$$
</div>




The proof is technical and can be found in Nualart's book
[1](https://books.google.co.uk/books?id=wI4fAwAAQBAJ&printsec=frontcover&hl=fr&source=gbs\U ge\U summary\U r&cad=0#v=onepage&q&f=false) on page 74. Let us try to understand the
formula and also the reason for the name of the semigroup. We consider
as at the beginning of this post the finite-dimensional case but now
with some Gaussian measure $\mu$


<div>
 $$\mu (A):=\int\U {A}e^{-\frac{\norm{x}^2}{2} } dx.$$
</div>

  Then, integration by
parts shows that

<div>
 $$\begin{aligned}
        \int\U \mathbb{R}^df(x) \cdot \nabla g(x) d\mu(x) & =-\int\U \mathbb{R}^d\nabla\cdot  \left(e^{-\frac{\norm{x}^2}{2} }f(x)\right) \nabla g(x) dx \\&=\int\U \mathbb{R}^d(x\cdot f(x)-\nabla\cdot f(x)) d\mu (x).
    \end{aligned}$$
</div>

  That is, the adjoint of the gradient in
$L^2({\mathbb R}^d,\mu )$ is $x\cdot -\nabla\cdot$. Notice that we get
the extra term that corresponds to multiplication by $x\cdot$.As a
result, the Laplacian on $L^2({\mathbb R}^d, \mu )$ is given by


<div>
 $$\Delta\U \mu =\nabla\cdot \nabla-x\cdot \nabla .$$
</div>

  Furthermore, by It√¥'s
formula, $\Delta\U \mu$ is the generator of the SDE


<div>
 $$dX(t)=-X(t)d t+ \sqrt{2}dW(t)$$
</div>

  Let us write $X\U x$ for the solution to
the above SDE with initial data $x \in {\mathbb R}^d$ That is, if we
define

<div>
 $$P\U tX(x):=E[\varphi(X(t))],$$
</div>

  then


<div>
 $$\partial \U tP\U tX(x)=\Delta\U \mu P\U tX(x) .$$
</div>

  The process $X$ that solves
the SDE above is known as the Ornstein-Uhlenbeck process and, by the
theory of linear SDEs, is given by


<div>
 $$X\U x(t)=e^{-t}x+\sqrt{2} \int\U {0}^te^{s-t} dW(t).$$
</div>

  Since


<div>
 $$\sqrt{2} \int\U {0}^te^{s-t} dW(t)\sim \sqrt{2} e^{-t}\mathcal{N}\left(0,\norm{e^\cdot }^2\U {L^2([0,t])}\right)=\sqrt{1-e^{-2t}}\mathcal{N}(0,1)$$
</div>


We deduce that for each fixed $t$ we can find a measure
$\gamma   \sim \mathcal{N}(0,1)$ with


<div>
 $$X(t)=e^{-t}x+\sqrt{1-e^{-2t}}\gamma .$$
</div>

  We then get that


<div>
 $$P\U t \varphi(x)=\mathbb{E}\left[\varphi\left(e^{-t}x+\sqrt{1-e^{-2t}}\gamma  \right)\right]$$
</div>


And by taking $\varphi=Id$ we recover Mehler's formula. This
correspondence is expanded on in chapter $7$ of Hairer's notes
[2](https://books.google.co.uk/books?hl=zh-CN&lr=&id=l\U 1uDwAAQBAJ&oi=fnd&pg=PR11&dq=nualart+introduction+malliavin&ots=\U JuMhMkTMt&sig=Tx5y00u4kMNs73jLtMEs-kyXAuU&redir\U esc=y#v=onepage&q=nualart\%20introduction\%20malliavin&f=false).
